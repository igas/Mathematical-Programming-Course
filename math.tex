\documentclass[12pt,a5paper]{scrbook}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{xfrac}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{multirow}
\usetikzlibrary{calc}
\usetikzlibrary{decorations.pathreplacing}
\usepgflibrary{shapes.misc}
\usetikzlibrary{intersections}
%\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[a5paper]{geometry}
\geometry{left=2.5cm}
\geometry{right=1.5cm}
\geometry{top=2cm}
\geometry{bottom=3cm}

% newline after \paragraph
\makeatletter 
\renewcommand\paragraph{\@startsection{paragraph}{4}{0mm}% 
{-\baselineskip} % 
{0.5\baselineskip} % 
{\normalfont\bfseries}}% 
\makeatother 

\begin{document}
  \pagestyle{plain}
  \begin{titlepage}
    \newgeometry{left=1cm,right=1cm,top=3cm,bottom=1cm}
    \begin{center}
      \Huge{Ю.~Я.~Зубарев}
    \end{center}
    \vfill
    \vfill
    \begin{center}
      \Large{\textbf{Математическое программирование\\
      Конспект лекций}}
    \end{center}
    \vfill
    \vfill
    \vfill
    \restoregeometry
  \end{titlepage}
  \tableofcontents
  \newpage
  Математическое программирование - это методы принятия оптимальных решений.\par
  История развития методов математического программирования:
  \begin{enumerate}
    \item Системы автоматизации управления.\\Появились работы по оптимальным автоматическим системам.
    \item Методы, связанные с ракетной техникой.\\Решалась задача об оптимальной траектории ракет.
    \item Решение военных, экономических и административных задач.
    \item Логистика.
  \end{enumerate}\par
  Существовала и классическая теория оптимизации, но она не получила распространения, т.к. не учитывает ограничений.\par
  Критерий оптимальности - это формализованное правило, позволяющее производить сравнительную оценку различных вариантов (решений, процедур, операций...) и выбор наилучшей из них.\par
  Любая система (процесс, операция) характеризуется какими либо операциями.\par
\{СХЕМА!\}
  \begin{enumerate}
    \item Астрономические наблюдения.\\Судно - материальная точка.
    \item Волнения.\\Судно - линейная стохастическая модель.
    \item Разворот судна в порту.\\Нелинейная модель.
  \end{enumerate}\par
  Цель: свести решение задачи к типовым программным продуктам.\par
  Математическая формулировка задачи\par
  \(
  k(q_1, q_2\ldots q_n)\to min (max)
  \)
  \par
  3 показателя ограничений:\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\geq k_{\rho_{min}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\leq k_{\rho_{max}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n) = k_{\rho_{0}}
  \)\par
  $\rho = 1, 2, \ldots m$ (обычно затраты) применяется редко\par
  Рассмотрим 1й случай:\par
  $k$ - линейные функции от параметров $q$. В этом случае мы рассматриваем задачи линейного программирования.\par
  $k$ - нелинейные функции. Тогда мы рассматриваем задачи нелинейного программирования. Размерность задачи нелинейного программирования 2\,--\,5 параметров.\par
  $q$ - целочисленные, тогда имеем дело с целочисленным программированием (линейным и нелинейным). Разбиение задачи на подзадачи.\par
  Стохастическое программирование - нам не известны точные значения $q$, но известны их вероятностные характеристики или интервалы изменения их значений.\par
  \chapter{Методы одномерной оптимизации}
  \pagestyle{headings}
  $$k(q)\to min(max)$$
  $$q_{min}\leq q \leq q_{max}$$
  Унимодальная функция
  \begin{figure}[h]
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[anchor=north] {};
    \draw[->] (0,-0.5)--(0,3.5) node[anchor=east] {};
    \draw (1,0) node[below]{$q_{min}$} .. controls (1.5,4) and (4.5,4) .. (5,0) node[below]{$q_{max}$};
    \draw[dashed] (3,0) node[below]{$q_0$} -- (3,3);
  \end{tikzpicture}
  \end{figure}
  \section{Методы с последовательным уменьшением интервала неопределенности}
  $\Delta_0 = q_{max} - q_{min}$ -- это интервал неопределенности.\par
  Функция униполярная $\Rightarrow$ мы можем уменьшить интервал неопределенности.
  \begin{center}
  \begin{tabular}{lcr}
  \begin{tikzpicture}[scale=0.5]
    \draw (0,0) -- (9,0);
    \draw (3,0) -- (3,1);
    \draw (6,0) -- (6,2);
    \draw[dashed] (3,0) -- (3,-1);
    \draw[dashed] (9,0) -- (9,-1);
    \draw[<->] (3,-1) -- (9,-1);
  \end{tikzpicture}
  &
  или
  &
  \begin{tikzpicture}[scale=0.5]
    \draw (0,0) -- (9,0);
    \draw (3,0) -- (3,2);
    \draw (6,0) -- (6,1);
    \draw[dashed] (0,0) -- (0,-1);
    \draw[dashed] (6,0) -- (6,-1);
    \draw[<->] (0,-1) -- (6,-1);
  \end{tikzpicture}
  \end{tabular}
  \end{center}
  \par
  Совершая различные вычисления, мы уменьшаем интервал неопределенности.
  \newpage
  \subsection{Метод дихотомии (деление пополам)}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (5,0);
    \draw (2,0) -- (2,0.75);
    \draw (3,0) -- (3,1.25);
    \draw (2.5,-0.05) -- (2.5,0.05);
    \draw[decorate,decoration=brace] (3,0) -- (2,0);
    \draw (2.5,0) node[below] {$\varepsilon$};
    \draw[decorate,decoration=brace] (2,0) -- (2.5,0);
    \draw (2.25,0.75) node[below] {$\sfrac{\varepsilon}{2}$};
    \draw[decorate,decoration=brace] (2.5,0) -- (3,0);
    \draw (2.75,0.75) node[below] {$\sfrac{\varepsilon}{2}$};
    \draw[|-|] (2,-0.75) -- (5,-0.75);
    \draw (3.25,-0.75) -- (3.25,-0.55);
    \draw (3.75,-0.75) -- (3.75,-0.35);
    \draw[|-|] (2,-1.5) -- (3.75,-1.5);
    \draw[dashed] (2,-1.5) -- (2,0);
    \draw[dashed] (5,0) -- (5,-0.75);
    \draw[dashed] (3.75,-1.5) -- (3.75,-0.75);
  \end{tikzpicture}
  \par
  Делим до тех пор, пока отрезок не будет достаточно мал.
  \par
  На каждой итерации 2 вычисления.
  \par
  $$\Delta_2 = \frac{\Delta_0}{2} + \frac{\varepsilon}{2}$$
  $$\Delta_4 = \frac{\Delta_0}{2^2} + \bigg(1 - \frac{1}{2^2}\bigg)\varepsilon$$
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}} + \bigg(\underbrace{1 - \frac{1}{2^{r/2}}}_{\rightarrow 1}\bigg)\varepsilon$$
  \par
  Если считать, что $\varepsilon$ можно пренебречь.
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}}$$
  \par
  Преимущество: Простота
  \par
  Недостаток: Плохая сходимость
  \subsection{Золотое сечение}
  Основан на следующий допущениях:
  \par
  $$\Delta_{r-1}, \Delta_r, \Delta_{r+1}$$
  \par
  \begin{enumerate}
    \item $\frac{\Delta_{r-1}}{\Delta_r} = \frac{\Delta_r}{\Delta_{r+1}} = \tau$
    \item $\Delta_{r-1} = \Delta_r + \Delta_{r+1}$\qquad /$:\Delta_{r+1}$
  \end{enumerate}
  $$\frac{\Delta_{r-1}}{\Delta_{r+1}} = \frac{\Delta_r}{\Delta_{r+1}} + 1$$
  $$\tau^{\,2} = \tau + 1$$
  $$\tau = 1,618$$
  \par
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (3,0);
    \draw (1,0) -- (1,1);
    \draw (2,0) -- (2,0.5);
    \draw[decorate,decoration={brace,raise=3pt}] (1.5,0) -- (0,0);
    \draw[decorate,decoration={brace,raise=3pt}] (3,0) -- (1.5,0);
    \draw (0.75,-0.1) node[below] {$\frac{\Delta_0}{\tau}$};
    \draw (2.25,-0.1) node[below] {$\frac{\Delta_0}{\tau}$};
    \draw (0.5,-0.9) node[below] {$\frac{\Delta_0}{\tau^{\,2}}$};
    \draw (0.5,-0.9) node[below] {$\frac{\Delta_0}{\tau^{\,2}}$};
    \draw[<->] (0,-0.9) -- (1,-0.9);
    \draw[dashed] (1,-0.9) -- (1,0);
    \draw[dashed] (0,-0.9) -- (0,0);
  \end{tikzpicture}
  \par
  На каждой итерации только одно вычисление, а на следующем берем результат предыдущего. На первой итерации 2 вычисления.
  \par
  $r$ - вычислений
  \par
  $(r-1)$ - итерация
  $$\frac{\Delta_0}{\Delta_r} = \tau^{r-1}$$
  \par
  Преимущества: хорошая сходимость.
  \par
  Недостатки: достаточная сложность алгоритма.
  \section{Шаговые методы}
  При каждом последующем шаге результат должен быть не хуже предыдущего.
  \par
  \subsection{Метод с постоянным шагом}
  \begin{center}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (5,0);
    \draw (1,0) -- (1,0.25);
    \draw (2,0) -- (2,0.5);
    \draw (1,0) node[below] {$q^{\,(1)}$};
    \draw (2,0) node[below] {$q^{\,(2)}$};
    \draw (1.5,0) node[above] {$\lambda$};
  \end{tikzpicture}
  \end{center}
  $$k\Big(q^{\,(2)}\Big)>k\Big(q^{\,(1)}\Big)\text{\;--\;вправо}$$
  $$k\Big(q^{\,(2)}\Big)<k\Big(q^{\,(1)}\Big)\text{\;--\;влево}$$
  $$k\big(q^{\,r+1}\big)<k\big(q^{\,r}\big)$$
  \begin{center}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (2,0);
    \draw (1,0) node[below] {$\lambda = \lambda'm$};
    \draw (0,0) node[above] {$\lambda_r$};
    \draw (2,0) node[above] {$\lambda_{r+1}$};
  \end{tikzpicture}
  \end{center}
  \subsection{Метод с переменным (пропорциональным) шагом}
  TODO: График??????
  $$q^{\,(3)} = q^{\,(2)} + \Theta\frac{k(q^{\,(2)}) - k(q^{\,(1)})}{\underbrace{q^{\,(2)} - q^{\,(1)}}_{\lambda}}$$
  $$q^{(r)} = q^{(r-1)} + \Theta = \frac{k(q^{r-1}) - k(q^{r-2})}{q^{(r-1)} - q^{(r-2)}}=\frac{k(q^{r-1}) - k(q^{r-2})}{\lambda}$$
  $$\Theta\frac{k\Big(q^{(2)}\Big) - k\Big(q^{(1)}\Big)}{\lambda}=\lambda$$
  $$\Theta = \frac{\lambda^2}{k(q^{(2)}) - k(q^{(1)})}$$
  \par
  Частный случай градиентного метода. Шаг зависит от вида поверхности.
  \subsection{Метод с переменным шагом с последующей квадратичной апроксимацией}
  $$k = TODO: дописать функцию$$
  TODO: график
  \par
  Увеличиваем шаг в 2 раза, TODO: дописать параграф
  $$q^{r+1} = q^r + \lambda \cdot 2^{r-2}$$
  $$\lambda_1 = 2^{r-3}$$
  \par
  Отбрасываем одну из крайних точек, которая наихудшая.
  $$q_{max(min)} = q_0 + \frac{\lambda_1}{2} \cdot \frac{k(q_-) - k(q_+)}{k(q_-) - 2k(q_0) + k(q_+)}$$
  \par
  Подставим наши значения:
  $$q_{max} = 8 + \frac{4}{2} \cdot \frac{91 - 75}{91 - 2 \cdot 99 + 75} = 8 + 2 \cdot \frac{+16}{-32} = 7$$
  \par
  Порядок действий:
  \begin{enumerate}
    \item С каждым шагом величина шага увеличивается вдвое.
    \item Движение продолжается до тех пор пока значение $k$ не начнет уменьшаться.
    \item Берется половина последнего интервала и определяется значение показателя в дополнительной точке. Из рассматриваемых 4-х точек отбрасывается точка с наименьшим(наибольшим) значением.
    \item По формуле определяется $max(min)$ квадратичной зависимости, которая проходит через 3 оставшиеся точки.
    \item В случае необходимости уменьшают на порядок интервал и заново начинаем процедуру с полученной экстремальной точки.
  \end{enumerate}
  \chapter{Основы нелинейного программирования}
  Множество - это совокупность раздельных объектов, рассматриваемых в данной задаче как единое целое.\par
  Конечное множество имеет конечное количество элементов меньше натурального числа $N$.\par
  Если множество упорядочено - это кортеж. Любая точка рассматривается как вектор.
  $$
    q^{(1)} =
    \begin{bmatrix}
      q_{11}\\
      q_{12}\\
      \vdots
    \end{bmatrix}
  $$
  $$\bar{q}^{\,1T}$$
  \par
  Между точками можно совершать операции и выделять соотношения.\par
  Есть 3 точки: $\bar{q}^{\,(1)}, \bar{q}^{\,(2)}, \bar{q}^{\,(3)}$
  \begin{enumerate}
    \item Аксиома идентичности\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = 0$
    \item Аксиома симметрии\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = (\bar{q}^{\,(2)}, \bar{q}^{\,(1)})$
    \item Аксиома треугольника\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(3)})\leq d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) + d(\bar{q}^{\,(2)}, \bar{q}^{\,(3)})$
  \end{enumerate}
  \par
  Если на множестве определены операции, то это множество обладает структурой (называют пространством)\par
  Если в пространство определяло расстояние (метрика), то пространство называют метрическим.
  
  \paragraph{Манхеттоновское расстояние}
  В судовых сетях прокладка кабеля осуществляется по манхеттеновскому расстоянию.
  $$d \left( \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)} \right) = \sum_{i=1}^n |\bar{q}_i^{\,\left(1\right)} - \bar{q}_i^{\,\left(2\right)}|$$
  
  \paragraph{Евклидово расстояние}
  $$
    d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^2
      \right]^{\frac{1}{2}}
  $$
  \par
  Общая формула расстояния:
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^p
      \right]^{\frac{1}{p}}
  $$
  \par
  Если $p \to \infty$,
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      = max
      \bigg[
        \Big(
          q_1^{(1)} - q_1^{(2)}
        \Big)
        \Big(
          q_2^{(1)} - q_2^{(2)}
        \Big)
        \ldots
        \Big(
          q_n^{(1)} - q_n^{(2)}
        \Big)
      \bigg]
  $$

  \paragraph{Бесконечное ограниченное множество}
  $d\big(\bar{q}^{(1)}, \bar{q}^{(2)}\big) < M$, то множество бесконечно, но ограничено.
  \begin{wrapfigure}{r}{3cm}
  \begin{tikzpicture}[scale=1.4]
    \draw (2,2) .. controls +(0,1) and +(-0.25,0.25) .. (3,3.5)
  				.. controls +(0.3,-0.2) and +(0.5,1) .. (3.5,2.5)
  				.. controls +(-0.2,-0.5) and +(0,-0.3) .. (2,2);
    \filldraw (2.5,2.3) circle (1pt) node[anchor=west] {$q_1$};  	
  	\filldraw (3,3) circle (1pt) node[anchor=west] {$q_2$};
  \end{tikzpicture}
  \end{wrapfigure}
  Сфера: \par
  $d\big(\bar{q}, \bar{a}\big) = R$\\
  Шар:\par
  Замкнутый: $d\big(\bar{q}, \bar{a}\big) \leq R$\par
  Открытый: $d\big(\bar{q}, \bar{a}\big) < R$\\
  Если все точки шара принадлежат точкам шара, то точка называется внутренней. Если некоторые области находятся вне шара, то она называется граничной.
  
  \paragraph{Выпуклые области}
  Пусть существуют $\bar{q}^{\,(1)}, \bar{q}^{\,(2)}$\,, и если $\lambda\bar{q}^{(1)} + (1 - \lambda)\bar{q}^{(2)} \in \Theta$, то область называется выпуклой.
  \par
  Область называется замкнутой, если все граничные области принадлежат ей.

  \paragraph{Теорема Вейерштрасса}
  Если функция определена в замкнутом ограниченном и непустом множестве (\textsc{зона}), то функция в этом множестве хотя бы один раз принимает $max$ и $min$ значения.
  \par
  Непустое множество - это множество содержащее хотябы одну точку.
  
  \paragraph{Рассмотрим виды экстремумов}
  \begin{tikzpicture}
    \clip (-1,-1) rectangle (10,7);
    \draw[->] (-0.5,0)--(9,0) node[anchor=north] {$q$};
  	\draw[->] (0,-0.5)--(0,6) node[anchor=east] {$k$};
  	\coordinate (a2) at (1,1);
  	\coordinate (a1) at (2,5);
  	\coordinate (a4) at (3,2);
  	\coordinate (a5) at (4,2);
  	\coordinate (a6) at (5,2);
  	\coordinate (a3) at (6,3.5);
  	\coordinate (x) at (7,1.5);
  	% dots
  	\filldraw ($(a2) +(.05,-.03)$) circle (1pt) node[right=3pt] {2};
  	\filldraw ($(a1) +(.2,.03)$) circle (1pt) node[above] {1};
  	\filldraw (a4) circle (1pt) node[below] {4};
  	\filldraw ($(a5) +(0,-.08)$) circle (1pt) node[below] {5};
  	\filldraw (a6) circle (1pt) node[below] {6};
  	\filldraw (a3) circle (1pt) node[above] {3};
  	% curve
  	\draw[name path=first curve] (0.5,6) .. controls ($(a2) +(0,-8)$) and ($(a1) +(0,5)$) .. (2.5,3.5);
  	\draw (2.5,3.5) ..controls ($(a4) +(-0.3,0.1)$) .. (a4);
  	\draw (a4) .. controls ($(a5) +(0,-.1)$) .. (a6);
  	\draw (a6) .. controls ($(a6) +(.3,.1)$) .. (5.5,3);
  	\draw (5.5,3) .. controls ($(a3) +(-.4,-.2)$) and ($(a3) +(-.2,0)$) .. (a3);
  	\draw (a3) .. controls ($(a3) +(.2,0)$) and ($(a3) +(.4,-.1)$) .. (6.5,3);
  	\draw (6.5,3) .. controls ($(x) +(-.2,.1)$) .. (x);
  	\draw[name path=last curve] (x) .. controls ($(x) +(0.3,0)$) .. (8,5);
  	% help lines
  	\draw[dashed] (1.05,0) node[below] {$q_{min}$} -- (1.05,6);
  	\draw[dashed,name path=help line] (7.5,0) node[below] {$q_{max}$} -- (7.5,6);
  	\fill [name intersections={of=last curve and help line, by={a7}}]
  	  (a7) circle (1pt) node[right] {7};
  \end{tikzpicture}\\
  Глобальный сильный максимум (1)
  $$k(\bar{q}_0) > k(\bar{q});\, q \in \Theta$$
  Глобальный сильный минимум (2)
  $$k(\bar{q}_0) < k(\bar{q});\, q \in \Theta$$
  Локальный сильный максимум (3)
  $$k(\bar{q}_0) < k(\bar{q});\, q_0 \in \Theta$$
  Локальный слабый минимум (4,5,6)
  $$k(\bar{q}_0) \geq k(\bar{q});\, q_0 \in \Theta$$
  Условный экстремум - точки лежащие на границе (2,7).\\
  Безусловный экстремум - точки лежащие внутри области.\par
  Где ищем экстремумы:
  \begin{enumerate}
  	\item Стационарные точки - точки, где экстремум равен нулю (безусловный экстремум).
  	\item Безусловный экстремум (точки, где нет производных).
  	\item Граничные точки (условный экстремум).
  \end{enumerate}
  
  \section{Классический метод оптимизации}
  $$k(q_1, q_2, \ldots, q_r)$$
  \begin{enumerate}
  	\item Считается что функция гладкая и имеет в каждой точке 1ю и 2ю производные.
  	\item Не учитываем ограничения ни на $q$, ни на $k$.
  \end{enumerate}
  $$q^{0T} = \Big[q_1^0, q_2^0, \ldots, q_n^0\Big]$$
  $$k(\bar{q}) = k(\bar{q}^0) + \sum_{i = 1}^n\Bigg(\frac{\partial k}{\partial q_i}\Bigg)_0\Delta q_i + \frac{1}{2}\sum^n_{i, j = 1}\Bigg(\frac{\partial^2 k}{\partial q_i\partial q_j}\Bigg)_0\Delta q_i\Delta q_j$$
  $$\Delta q_i = q_{i_0} - q_i$$
  $$\Delta q_j = q_{i_0} - q_j$$
  \par
  Если точка стационарная, то $\sum\Big(\frac{\partial k}{\partial q_i}\Big)_0 = 0$, тогда
  $$k(q^0) - k(\bar{q}_1) = - \frac{1}{2}\sum_{i, j = 1}^n\left(\frac{\partial^2k}{\partial q_i\partial q_j}\right)_0 \Delta q_i\Delta q_j$$
  \par
  Максимуму соответствует отрицательная квадратичная форма:
  $$\frac{\partial^2k}{\partial q_i q_j} = a_{ij}$$
  \par
  Введем матрицу Гессе:
  $$
  	\mathcal{J}(\bar{q}) =
  	\begin{bmatrix}
  	  a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
  	  a_{21} & a_{22} & a_{23} & \cdots & a_{2n}\\
  	  \vdots & \vdots & \vdots & \ddots & \vdots\\
  	  a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}\\
  	\end{bmatrix}
  $$
  \par
  Квадратическая форма
  $$\bar{q}^T\mathcal{J}(\bar{q})\bar{q}$$
  \par
  Необходимо определить свойства этой квадратичной формы. Рассмотрим определитель матрицы Гессе - гессиан.
  \paragraph{Критерий Сильвестра}
  Если все ограничения положительны, то мы имеем положительную квадратичную форму, значит $min$.
  \par
  Если определители меняют знак (знакопеременные) то, тогда квадратичная форма отрицательная, следовательно мы имеем дело с $max$.
  \par
  Если не соблюдается ни первое, ни второе условия, такая точка - седло.
  \par
  Методом редко пользуются потому что:
  \begin{enumerate}
  	\item Слишком много допущений;
  	\item в аналитическом виде решение частных производных вычислить трудно, т.к. матрицу Гессе трудно определить.
  	\item не учитываются ограничения.
  \end{enumerate}
  \section{Метод множителей лагранжа}
  Допущения:
  \begin{enumerate}
  	\item Функция гладкая и в каждой точке имеет 1-ю и 2-ю производные.
  	\item $k_\rho = k_{\rho0}; \; \rho = 1,2,\ldots,m$  		
  \end{enumerate}
  $$L(\bar{q}) = k(\bar{q}) + \sum_{\rho=1}^{m} \lambda_\rho[k_{\rho_0} - k_\rho(\bar{q})]$$
  $\lambda_\rho$ --- множитель Лагранжа.
  $$\frac{\partial L}{\partial q_i} = \frac{\partial k}{\partial q_i} - \sum_{\rho=1}^{m} \lambda_\rho \frac{\partial k_\rho(\bar{q})}{\partial q_i} = 0; \; i=1,2,\ldots,n$$
  $$\frac{\partial L}{\partial \lambda_\rho} = [k_{\rho_0} - k_\rho] = 0;\; \rho=1,2,\ldots,m$$
  Получилась система из $n+m$ уравнений. Если решим систему, получим аналитическое решение задачи.
  
  \paragraph*{Пример}
  Задача имеет смысл, когда $p=1$\\
  $max\; p$ \\
  Есть:\par
  m - масса \par
  v - объём \par
  c - экономия \par
  p - вероятность безотказной работы
  $$max\; p$$
  $$m(v,c) \leq m(v_0,c_0)$$
  \begin{center}
	либо $min(m,v,c)$ при $p \geq p_0$
  \end{center}
  
  \section{Поисковые методы}
  Последовательное вычисление, причём следующий шаг должен быть лучше предыдущего.\par
  Рассмотрим условия, когда локальный экстремум является глобальным. Рассмотрим понятия выпуклой и вогнутой функции.\\
  $$z = \lambda (k(\bar{q}') + (1-\lambda)k(\bar{q}''))$$  
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[below=4pt] {$q$};
  	\draw[->] (0,-0.5)--(0,4) node[left] {$k$};
  	\draw[dashed] (1.5,0) node[below] {$q'$} -- ++(0,1.5) -- ++(3,1) -- ++(0,-2.5) node[below] {$q''$};
  	\draw (1.5,1.5) .. controls (2,2) and (3,3) .. (4.5,2.5);
  	\draw (1.5,1.5) .. controls (2,1) and (4,1.5) .. (4.5,2.5);
  	\draw (4,3) -- ++(0.5,0.75) node[above] {Выпуклая};
  	\draw (4,1.75) -- ++(1,-0.25) node[right] {Вогнутая};
  \end{tikzpicture}
  $$k[\lambda \bar{q}' + \left(1-\lambda q''\right)] \leq Z = \lambda k(\bar{q}') + (1-\lambda)k(\bar{q}')$$
  Если знак неравенства $\leq$ - имеем дело с выпуклой функцией.\\
  Если неравенство строгое - строго выпуклая функция.\\
  Если знак $\geq$, то функция вогнутая.\\
  Если $=$, то не строго выпуклая и не строго вогнутая.\par
  Если на выпуклом множестве определена \emph{вогнутая} функция, тогда локальный \emph{максимум} является глобальным. Если же на выпуклом множестве определена \emph{выпуклая} функция, тогда локальный \emph{минимум} является глобальным.
  
  \section{Метод Гаусса-Зейделя}
  Функция $k(q_1, q_2, \ldots, q_n);\;q_1, q_2, \ldots, q_n = const $
  \begin{enumerate}
    \item $max(min(k(q_1)))$ \\
      \begin{tikzpicture}
  	    \draw[->] (-0.5,0)--(4,0) node[anchor=north] {$q_1$};
  	    \draw[->] (0,-0.5)--(0,4) node[anchor=east] {$q$};
  	    \draw (2,2) -- +(-0.5,0) -- +(-0.5,0.5) -- +(0.5, 0.5) -- +(0.5,-0.5) -- +(-1,-0.5) -- +(-1,1) -- +(1,1) -- +(1,-1) -- +(-1,-1);
      \end{tikzpicture}
    \item $min(max(k(q_1)))$ \\
      \begin{tikzpicture}
        \draw[->] (-0.5,0)--(4,0) node[anchor=north] {$q$};
  	    \draw[->] (0,-0.5)--(0,4) node[anchor=east] {$k$};
  	    \draw (1,1) -- ++(1,0) -- ++(0,1) -- ++(0.5,0) -- ++(0,0.5) -- ++(0.25,0) -- ++(0,0.25) -- ++(0.12,0);
      \end{tikzpicture}
  \end{enumerate}
  $$|q_i^{r+1} - q_i^r| \leq \epsilon_i - q_n$$
  $$|k^{r+1} - k^r| \leq \eta $$
  Недостаток: плохая сходимость. Обычно решается для $n<3$.

  \section{Градиентный метод оптимизации (первого порядка)}
  Идея: ищут стационарную точку (безусловный экстремум) равных значений показателя.\\
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[anchor=north] {$q_1$};
  	\draw[->] (0,-0.5)--(0,5) node[anchor=east] {$q_2$};
  	\draw (3,2.9) circle[x radius=2mm, y radius=1mm, rotate=30];
  	\draw (2.5,2.5) .. controls +(1mm,6mm) and +(-1mm,4mm) .. (3.5,3)
  					.. controls +(0,-4mm) and +(0,-2mm) .. (2.5,2.5);
  	\draw (2,2) .. controls +(0,1) and +(-0.25,0.25) .. (3,3.5)
  				.. controls +(0.3,-0.2) and +(0.5,1) .. (3.5,2.5)
  				.. controls +(-0.2,-0.5) and +(0,-0.3) .. (2,2);
  	\draw (1.5,1.5) .. controls +(0.1,2.5) and +(0.3,2) .. ++(3	,2)
  					.. controls +(0,-1) .. ++(-0.5,-1.5)
  					.. controls +(-0.5,-0.5) and +(-0.1,-0.8) .. (1.5,1.5);
  	\coordinate (a) at (1,2);
  	\coordinate (b) at ($(a) +(49:4cm)$);
  	\draw (a) -- (b);
  	\coordinate (c) at ($ (a)!0.50!(b) $);
  	\coordinate (d) at ($ (c)!1cm!-90:(b) $);
	\draw[->] (c) -- (d);	
  	\draw (4.3,4.7) -- ++(1,0.25) node[anchor=west] {кривые равных значений};
	\draw (5.3,4.6) node[anchor=west] {показателя};
	\draw (2.8,3.3) -- (5.3,4) node[right] {направление крутого};
	\draw (5.3,3.7) node[right] {восхождения};
  \end{tikzpicture}
  $$
    \nabla k(\bar{q}^{\,r}) =
    \begin{bmatrix}
      \frac{\partial k}{\partial q_1}\\
      \frac{\partial k}{\partial q_2}\\
      \vdots\\
      \frac{\partial k}{\partial q_n}\\
    \end{bmatrix}
  $$
  \par
  Направление наибольшего возрастания показателя и будет направлением градиента.
  \par
  Противоположное ему направление называется антиградиентом(отрицательным градиентом).
  \par
  С каждым шагом мы вычисляем новое направление градиента, с тем чтобы двигаться к экстремуму.
  $$\bar{q}^{\,r+1} = \bar{q}^{\,r} + \Theta\nabla k(\bar{q}^{\,(r)}),$$
  где $\Theta$ - величина шага.
  $$\bar{q}_i^{\,r+1} = \bar{q}^{\,r} + \Theta\bigg(\frac{\partial k}{\partial q_i}\bigg)_r$$
  \par
  Иногда вектор градиент нормируется
  $$\nabla k^{\,r}_{\,n}(\bar{q}^{\,r}) = \frac{\Delta k(q_n)}{\Big[\sum_{i=1}^n\big(\frac{\partial k}{\partial q_i}\big)\Big]^{\frac{1}{2}}}$$
  Выбор шага:
  \begin{enumerate}
    \item Метод с постоянным шагом
    \item С оптимальным шагом
  \end{enumerate}
  При большем шаге мы можем пропустить экстремум и процесс будет расходящимся.
  
  \section{Метод с оптимальным шагом}
  Есть $k$ в точке $r+1$
  $$k(\bar{q}^{r+1}) = k[\bar{q}^r + \Theta\nabla k(\bar{q}^r)]$$
  Ищем $\Theta$, которое соответствует $max(k(q^{r+1}))$ и $min$, если мы решаем задачу на минимум.\\
  Мы свели задачу многомерной оптимизации к задаче одномерной оптимизации. Условная функция должна быть гладкая и должны существовать по крайней мере две производные; и матрица Гессе должна быть знакоопределённая.\\
  Если мы попадём в седло, то из этой точки надо вылезать с помощью другого метода. Если функция гладкая и имеет 3 производных, то градиентный метод сходится при $r \rightarrow \infty$. Если функция квадратичная, то мы приходим к экстремуму за конечное число шагов.
  \paragraph*{Ограничение значений параметра}
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(7,0) node[anchor=north] {$q_1$};
  	\draw[->] (0,-0.5)--(0,5) node[anchor=east] {$q_2$};
    \draw (1,1) rectangle (6,4);  	
  	\coordinate (a) at (2,2.5);
  	\coordinate (b) at (5.5,5);
  	\coordinate (c) at ($ (a)!0.60!(b) $);
  	\draw                             (a) -- (b);
  	\draw [decorate,decoration={brace,raise=5pt}] (a) -- (b) node[pos=0.45,above=10pt] {$\Theta_{\text{опт}}$};
  	\draw [decorate,decoration={brace,mirror,raise=5pt}] (a) -- (c) node[pos=0.7,below=12pt] {$\Theta_{\text{доп}}$};
  	\draw[->] (5.25,4) -- +(0,-1);
  	\node[cross out, draw, inner sep=3pt] at (5.25,4) {};
  \end{tikzpicture}
  $$\Theta_r = min[\Theta_{\text{доп}} - \Theta_{\text{опт}}]$$
  $$\Theta_{\text{доп}} - \text{допустимое}$$
  $$\Theta_{\text{опт}} - \text{оптимальное}$$
  Отбрасываем переменную, которая вышла за границу и пытаемся решить задачу без неё. Вычисляем производную по $q_2$. Если она направлена вниз, то мы движемся внутрь области, если вверх - за пределы области; считаем эту точку оптимальной.\\
  Преимущества: 
  \begin{itemize}
    \item Классический эталонный метод.
  \end{itemize}
  Недостатки: 
  \begin{itemize}
    \item Сложность вычисления производных.
    \item Численные методы могут давать большие ошибки.
    \item Метод по своей сути не рассчитан на учёт ограничений.
  \end{itemize}
  \section{Градиентный метод (второго порядка)}
  $$k(q^{\,r+1}) = k(\bar{q}^{\,r}) + \sum_{i = 1}^n\bigg(\frac{\partial k}{\partial q_1}\bigg)_r\Delta q_ir + \frac{1}{2}\sum^{n}_{i,j=1}\bigg(\frac{\partial^{\,2}k}{\partial q_i\partial q_j}\bigg)_r\Delta q_ir\Delta q_jr$$
  $$\Delta q_ir = q_i^{\,r+1} - q_i^{\,r}$$
  $$\Phi_r = k(\bar{q}^{\,r+1} - k(\bar{q}^{\,r})$$
  \par
  В матричной форме
  \begin{equation}\label{eq:quad}
    \Phi^{\,r} = \overbracket[0.5pt][7pt]{\nabla^{\,T}\underset{\mathclap{\begin{matrix}\uparrow\\\text{\scriptsize{вектор}}\\\text{\scriptsize{строка}}\end{matrix}}}{k}(\bar{q}^{\,r})\bar{\Delta}\underset{\mathclap{\begin{matrix}\uparrow\\\text{\scriptsize{вектор}}\\\text{\scriptsize{столбец}}\end{matrix}}}{q^{\,2}}}^{\mathclap{\text{при умножении получается число}}}+\frac{1}{2}(\Delta\bar{q}^{\,r})^{\,T}\mathcal{J}(\bar{q}^{\,r})_\Delta\bar{q}^{\,r}
  \end{equation}
  \par
  \ref{eq:quad} - квадратичная форма.
  \begin{equation}\label{eq:up}
    \frac{d \phi^{\,r}}{d \bar{\Delta}q^{\,r}}
  \end{equation}
  \par
  \ref{eq:up} - метод наискорейшего восхождения(спуска, если решаем задачу на $min$)
  \par
  В формуле \ref{eq:quad} возьмем производную по первому и второму слогаемому
  $$\nabla k(\bar{q}^{\,r}) + \mathcal{J}(\bar{q}^{\,r})\Delta\bar{q}^{\,r} = 0$$
  $$\mathcal{J}(q\,')\bar{\Delta} q^{\,r} = \nabla k(\bar{q}^{\,r})$$
  \par
  Умножаем на матрицу, обратную матрице $\mathcal{J}$.
  $$\underbrace{\mathcal{J}^{\,-1}(\bar{q}^{\,r})\mathcal{J}(\bar{q}^{\,r})}_{\mathclap{\text{E - единичная матрица}}}\bar{\Delta}q^{\,r} = \mathcal{J}^{\,-1}(q^{\,2})\nabla k(\bar{q}^{\,2})$$
  \par
  \begin{equation}\label{eq:cool}
    \bar{\Delta}q^{\,r} = \mathcal{J}^{\,-1}(q^{\,r})\nabla k(\bar{q}^{\,r})
  \end{equation}
  \par
  \ref{eq:cool} - направление самого крутого восхождения или наискорейшего спуска.
  \begin{equation}
    \bar{q}^{\,r+1} = \bar{q}^{\,r} - \Theta\mathcal{J}^{\,-1}(\bar{q}^{\,r})\nabla k(\bar{q}^{\,r})
  \end{equation}
  \par
  Окончательное выражение для градиентного метода второго порядка(метода Ньютона)
  \par
  Если функция $k$ - квадратичная, то оптимальная точка достигается за один шаг и точка берется равной 1.
  \paragraph*{Пример}
  $$
    \mathcal{J} =
    \begin{bmatrix}
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{bmatrix}
  $$
  $$
    \tilde{\mathcal{J}} =
    \begin{bmatrix}
      a_{22} & -a_{21}\\
      -a_{12} & a_{11}
    \end{bmatrix}
  $$
  $$
    \mathcal{J} = \frac{1}{\Delta}\mathcal{\tilde{J}}
  $$  
  $$k = (q_1 - 5)^2 + (q_2 - 8)^2 + (q_1 - q_2)^2$$
  Найти минимум функции.\\
  Начальные условия:\\
  $q^0 = 
  \begin{bmatrix}
    0 \\ 
    0    
  \end{bmatrix}$
  $$\frac{\partial k}{\partial q_1} = 2(q_1 - 5) + 2(q_1 - q_2) = -10$$
  $$\frac{\partial k}{\partial q_2} = 2(q_2 - 8) - 2(q_1 - q_2) = -16$$
  $$\frac{\partial^2k}{\partial q_1^2} = 2 + 2 = 4$$
  $$\frac{\partial^2k}{\partial q_2^2} = 2 + 2 = 4$$
  $$\frac{\partial^2k}{\partial q_1 \partial q_2} = -2$$  
  $$\mathcal{J} = 
  \begin{bmatrix}
    4 & -2 \\
    -2 & 4
  \end{bmatrix} - \text{Матрица Гессе}$$
  $$\mathcal{\tilde{J}} = 
  \begin{bmatrix}
    4 & 2 \\
    2 & 4
  \end{bmatrix}  
  $$
  $$\Delta = 16 - 4 = 12$$
  $$\mathcal{J}^{-1}(\bar{q}) = \frac{1}{12}\begin{bmatrix}
    4 & 2 \\
    2 & 4
  \end{bmatrix}$$
  $$\nabla k = \begin{bmatrix}
    -10 \\
    -16
  \end{bmatrix}$$
  Всё это справедливо только в нулевой точке.
  $$\bar{q}_0 = \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} - \begin{bmatrix}
    \frac{1}{3} & \frac{1}{6} \\[0.3em]
    \frac{1}{6} & \frac{1}{3}
  \end{bmatrix} \ast \begin{bmatrix}
    -10 \\
    -16
  \end{bmatrix} = \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} + \begin{bmatrix}
    \frac{1}{3}\cdot 10 + \frac{1}{6}\cdot 16 \\
    \frac{1}{6}\cdot 10 + \frac{1}{3}\cdot 16
  \end{bmatrix} = \begin{bmatrix}
    6 \\
    7
  \end{bmatrix}$$
  \textit{Перемножение матриц: первая строка на первый столбец; вторая строка на первый столбец.}\\
  Подставим в выражение $q_0$ и получим минимум $k=3$.\par
  Преимущество: высокая скорость сходимости.
  Недостаток: сложность вычисления матрицы Гессе. 
  
  \chapter{Симплексные методы оптимизации.}
  
  \section{Сравнительная оценка методов многомерной оптимизации}
  \begin{enumerate}
    \item Вопрос о точности результата.
    \[
      \left.
        \begin{aligned}
          &\text{- интервал неопределённости}\\
          &\text{- конечная величина шага}
       \end{aligned}
     \right\}
     \, 
       \begin{aligned}
         &\text{Одномерные}\\ 
         &\text{оптимизации}
       \end{aligned}
    \]
    Многомерные: точность определяется по нескольким параметрам, ошибка по всем параметрам не должна превышать какого-то числа.
    \begin{itemize}
      \item[-] решение зависит от масштаба переменных.
      \item[-] разная степень влияния.
    \end{itemize}
    
    \item Вопрос о допущениях.\\
    Множество должно быть выпуклое (область), показатель --- выпуклый или вогнутый.
    
    \item Эффективность алгоритма.\\
    Число итераций\\
    Глобальный локальный экстремум
  \end{enumerate}
  Симплекс методы обеспечивают наивысшую эффективность решения задачи.
  
  \section{Симплекс метод с постоянным шагом.}
  Симплекс многогранник.\\
  $n+1$ вершина, все вершины должны лежать в $n$-мерном пространстве (Евклидовом) и не могут лежать в пространстве меньшей размерности.
  
  Обычно рассматривают прав. симплексы --- рёбра (расстояния между вершинами) одинаковые.\\\newline
  0-мерный симплекс --- точка в пространстве, $n=0$\\
  1-мерный --- отрезок, $n=1$\\
  2-мерный --- треугольник, $n=2$\\
  3-мерный --- пирамида\\
  
  В общем случае можно записать в виде координат вершин. Пусть одна из вершин лежит в начале координат.

  $$
  D=
  \begin{bmatrix}
    \bar{q}_0 \\
    \bar{q}^{\,|1|} \\
    \bar{q}^{\,|2|} \\
    \vdots \\
    \bar{q}^{\,|n|}
  \end{bmatrix}    
  =
  \begin{bmatrix}
    0   & 0   & \cdots & 0 & 0     \\
    d_0 & d_1 & \cdots & d_1 & d_1 \\
    d_1 & d_0 & \cdots & d_1 & d_1 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    d_1 & d_1 & \cdots & d_1 & d_0
  \end{bmatrix}
  $$  
  
  Диагональные элементы --- $d_0$, остальные $d_1$. Диагональная матрица.
  
  $$
  d_0 = \frac{L_0}{n\sqrt{2}} \left[\sqrt{n+1}+n-1\right]
  $$
  $L_0$ --- величина ребра симплекса.
  $$
  d_1 = \frac{L_0}{n\sqrt{2}} \left[\sqrt{n+1}-1\right]
  $$
  
  Задаём опорную вершину --- $q_0$:
  $$
  q_0 = \left[q_1^0, q_2^0, \dotsc, q_n^0\right]
  $$
  
  Чтобы переместить симплекс нужно ко всем элементам 1 столбца прибавить $q_1$, 2 столбца --- $q_2$ и~т.д.\\
  
  Исходные данные --- $L_0$, $n$, координаты опорной точки.\\
  
  Для случая $n=2$: для max задан симплекс
  
  \begin{tikzpicture}[scale=1.2]
    \draw (0,0) node[below left]{0} -- (1,1.732) node[above left]{$n$} -- (2,0) node[below right]{1}  -- (0,0);
    \draw[dashed] (2,0) -- (3,1.732) node[above right]{$n+1$} -- (2,3.464) node[above]{$n+2$} -- (1,1.732) -- (3,1.732) -- (0,0);
  \end{tikzpicture}
  
  В каждой из вершин вычислим значения оптимизационного показателя $K(\bar{q}^{\,u})$.\\
  $u$ --- номер вершины, $u=1,2,\dotsc,n$;\\
  0-вершина --- наихудшая степень показателя.
  $$K(\bar{q}^{\,0}) < K(\bar{q}^{\,u}),\quad u=1,2,\dotsc,n$$
  $n$ --- наилучшая вершина.\\
  
  Направление отражения в первом приближении совпадает с направление вектора градиента. Чем меньше величина симплекса, тем больше совпадает.\\
  
  Точка в середине $\bar{q}_{w_0}$ --- центр тяжести всех вершин за исключением наихудшей.
  $$\bar{q}_{w_0} = \frac{1}{n} \sum_{u=1}^{n} \bar{q}^{|u|}$$
  справедливо для $n>2$
  $$\bar{q}_{w_0} - \bar{q}_0 = \bar{q}^{\,n+1} - \bar{q}_{w_0}$$ 
  
  \paragraph{Формула отражения:}
  $$\bar{q}^{\,n+1} = 2\bar{q}_{w_0} - \bar{q}_0;$$
  или
  $$\bar{q}^{\,n+1} = \left[ \frac{2}{n}\sum_{u=1}^{n} \bar{q}^{|u|} \right] - \bar{q}_0$$
  
  Допустим, $n+1$ вершина не самая худшая
  $$K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,(1)})$$
  1 --- вторая наихудшая после 0.\\
  
  Рассмотрим $1,n,n+1$ --- отражаем вершину 1: $n+2$. Получим аналог градиентного метода с постоянным шагом. Шаг определяется размером ребра симплекса.
  
  \paragraph{Операция колебания.}
  \begin{tikzpicture}[scale=1.2]
    \draw (0,0) node[below left]{0} -- (1,1.732) node[above]{$n$} -- (2,0) node[below right]{1}  -- (0,0);
    \draw (2,0) -- (3,1.732) node[above]{$n+1$}  -- (1,1.732);
    \draw[dashed] (3,1.732) -- (0,0) -- (-1,1.732) node[above]{$n+2$} -- (1,1.732);
    \draw [->] (0,2.5) arc (135:60:30pt);
  \end{tikzpicture}
  
  $$K(\bar{q}^{\,n+1}) < K(\bar{q}^{\,(1)})$$
  Если не введём дополнительное правило, возникнут колебания. Тогда возвращаемся в исходный симплекс и отражаемся в вершину 1. Процесс закончен, если симплекс вращается вокруг одной точки.\\
  
  \begin{wrapfigure}{l}{5cm}
  \begin{tikzpicture}[scale=1.5]
    \draw (0,0) rectangle (2,2);
    \draw (0,0) -- (2,2);
    \draw (0,2) -- (2,0);
    \draw (1,0) -- (1,2);
    \draw[->] (-.5,.5) arc (215:135:20pt);
    \draw[->] (2.5,1.5) arc (45:-45:20pt);
  \end{tikzpicture}  
  \end{wrapfigure}
  
  $$N_{\text{раз}} > 1.65n + 0.05n^2$$
  
  (для $n=2 N=4$)\\
  В этом случае выдача последних данных.\newline
  
  \paragraph{Учёт ограничений:}
  После каждого отражения проверка:
  \begin{itemize}
    \item[-] параметров
    \item[-] показателей ограничений (не вышли ли за пределы)
  \end{itemize}
  Если вышли --- наихудшая точка.\\
  
  \textbf{Преимущества:}\\
  Достаточно высокая эффективность:
  \begin{enumerate}
    \item Направление отражения совпадает с направлением вектора градиента.
    \item Достаточно одной операции вычисления (классический метод --- $n+1$ вычислений.
  \end{enumerate}
  Не накладывает ограничения на вид функции.\\
  В любой точке можно изменить число факторов (строим новый симплекс)\\
  Можем учитывать любые ограничения.\\
  
  \paragraph{Недостатки:}
  \begin{itemize}
    \item[-] Он соответствует градиентному методу с постоянным, но не оптимальным шагом.
    \item[-] Ищет локальный, но не глобальный экстремум.
    \item[-] Точность ограничена размером симплекса.
    \item[-] Все вершины исходного симплекса должны лежать в области дополнительных значений параметров.
  \end{itemize}
  
  \section{Симплекс с переменным шагом}
  \paragraph{Изменение размера симплекса, но сохранение формы.}
  Рассмотрим первую модификацию.\\  

  \begin{tikzpicture}[scale=1.5]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above left]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[above right]{$n+1$} -- (n);   
    \coordinate (1') at ($ (one)!.25!(n+1) $) (1') node[below right]{$1'$};
    \coordinate (n') at ($ (n)!.25!(n+1)$) (n') node[above left]{$n'$};
    \draw (1') -- (n') -- +(60:1.5) node[above]{$n+2$} -- (n+1);
    
    \draw[<->] ([yshift=-9pt] 0,0) -- ([yshift=-9pt] one) node [sloped,midway,fill=white]{$L_0$};
    
  \end{tikzpicture}
  
  $n$ --- Наилучшая точка.\par
  $0$ --- Наихудшая точка.\par
  $n+1$ --- Не наихудшая.\par
  $L_0$ --- Размер исходного симплекса.\\
  
  Мы не вычисляем значение показателя в вершине ?, т.~к. нам надо выбрать наихудшую вершину. Делаем предположение, что это $1'$. С каждым шагом размер симплекса уменьшается. Производим только одно вычисление. Остаётся постоянная отражённая вершина, все остальные меняются и подтягиваются к отражённой.\\
  
  Рассмотрим вторую модификацию.\\
  \begin{tikzpicture}[scale=1.5]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above left]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[below right]{$n+1$} -- (n);    
    \coordinate (1') at ($ (one)!.25!(n) $) (1') node[below left]{$1'$};
    \coordinate (n+1') at ($ (n+1)!.25!(n) $) (n+1') node[above right]{$n+1'$};
    \draw (1') -- (n+1') -- +(120:1.5) node[above]{$n+2$} -- (n);
  \end{tikzpicture}
  
  $K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,n})$; Подтягиваемся к $n$.\\
  
  Если отражённая вершина наилучшая, то обе вершины на данном шаге совпадают. 
  $$L_r = l_0 + \gamma_0$$
  
  $\gamma_r$ --- зависимость; при $\gamma_0 = 1,\;r\rightarrow\infty\quad \gamma\rightarrow\infty$\\
  Можем подобрать любую зависимость,\\
  $$\gamma_r = \frac{1}{1+d_r}$$ 
  \begin{center}Гиперболическая зависимость.\end{center}
  Близко --- метод составления наилучшей вершины.
  $$\gamma_r = e^{-\mu r}$$ 
  \begin{center}Более плавно уменьшается.\end{center}
  Составляет отражение тогда, когда исходная точка далеко от экстремума.\\
  
  Если плохо выбрана $\gamma$, то размер симплекса будет мал; следовательно эффект уменьшается.
  $$L_r \geq L_{min}$$
  Если в результате пришли к $L_{min}$, то меньший размер симплекса не берём и следовательно метод приходит к методу с постоянным шагом.\\
  
  \textbf{Преимущества:}\newline
  При правильном $\gamma_r$ эффект метода возрастает, т.~к. число шагов уменьшается. Симплекс мал, чтобы обеспечить эффективность.\\
  
  \textbf{Недостатки:}\newline
  -- Метод с переменным, но не оптимальным шагом.\\
  -- $\gamma_r$ задаём не исходя из свойств оптимизированной поверхности.
  
  \section{Метод деформированного многогранника.} %Nelder–Mead method
  Задачи:
  \begin{enumerate}
    \item выбор оптимального шага
    \item многогранник может быть неправильным
  \end{enumerate}
  
  \paragraph{1. Отражение}
  \begin{tikzpicture}[scale=1.5]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above left]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[above right]{$n+1$} -- (n);
    \draw[name path=diagonal1] (0,0) -- (n+1);
    \path[name path=diagonal2] (n) -- (one);
    \draw [name intersections={of=diagonal1 and diagonal2, by=x}] 
      coordinate (a) at ($ (x)!.8!(n+1) $)
      coordinate (b) at ($ (x)!.6!(n+1) $)
      (x) node[below=5pt]{$\bar{q}_{w_0}$};
    
    \draw (n) -- (a) -- (one);
    \draw (n) -- (b) -- (one);
  \end{tikzpicture}
  
  $\bar{q}_{w_0}$ --- центр тяжести всех вершин, кроме наихудшей.
  $$\bar{q}_{w_0} = \frac{1}{n} \sum_{u=1}^n q u$$
  $$\bar{q}_{n+1} = \bar{q}_{w_0} + \lambda( \bar{q}_{w_0} - \bar{q}_0),\;\; \lambda=0.8\div1.2$$
  Если $\lambda=1$, то симплекс будет правильным $\Rightarrow$ метод с постоянным шагом.
  
  \paragraph{2. Растяжение.}
  \begin{tikzpicture}[scale=1.5]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above left]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[above left]{$n+1$} -- (n);
    \draw (0,0) -- ($ (0,0)!2!(n+1) $) coordinate (n+2) node[right]{$n+2$};
    \draw (one) -- (n+2) -- +(120:2) node[above]{$n+3$} -- (n) -- (n+2);
  \end{tikzpicture}

  Вычисление значения показателя в точке $n+1$.\par
  $n+1$ --- лучшая в новом симплексе.
  $$K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,n})$$
  $$\bar{q}_{n+2} = \bar{q}_{w_0} + \beta(\bar{q}_{n+1} - \bar{q}_{w_0}),\;\;\beta=2\div3$$
  Продолжаем двигаться в этом направлении, получаем симплекс $(1,n,n+2)$
  $$K(\bar{q}^{\,n+2}) > K(\bar{q}^{\,n+1})$$
  Отбросим наихудшую вершину, отражаем $(1,n,n+2)$, получаем $(n,n+2,n+3)$. Если
  $$K(\bar{q}^{\,n+3}) > K(\bar{q}^{\,n+2})$$
  то возвращаемся и отражаем $(1,n,n+1)$.
  
  \paragraph{3. Сжатие.}
  Если $n+1$ наихудшая лучшая в старом.
  $$K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,1})$$
  $$K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,0})$$
  \begin{tikzpicture}[scale=2]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[above right]{$n+1$} -- (n);
    \draw[dashed,name path=diagonal1] (0,0) -- (n+1);
    \path[name path=diagonal2] (n) -- (one);
    \draw [name intersections={of=diagonal1 and diagonal2, by=x}] 
      coordinate (n+2) at ($ (0,0)!.7!(x) $)
      (x) node[right=5pt]{$\bar{q}_{w_0}$};    
    \draw (one) -- (n+2) node[below=4pt]{$n+2$} -- +(120:2) node[above]{$n+3$} -- (n) -- (n+2);
  \end{tikzpicture}
  
  $$\bar{q}_{n+2} = \bar{q}_0 + \gamma(\bar{q}_{w_0} - \bar{q}_0),\;\;\gamma=0.4\div0.6$$
  Если
  $$K(\bar{q}^{\,n+2}) > K(\bar{q}^{\,1})$$
  то рассматриваем $(1,n,n+2)$, получаем $(n,n+2,n+3)$.\\
  Если 
  $$K(\bar{q}^{\,n+2}) > K(\bar{q}^{\,1})$$
  то операция сжатия не получится, переходим к операции редукции.
  
  \paragraph{4. Редукция.}
  \begin{tikzpicture}[scale=2]
    \draw (0,0) node[below left]{0} -- +(60:2) coordinate (n) node[above left]{$n$} -- +(0:2) coordinate (one) node[below right]{1}  -- (0,0);
    \draw (one) -- +(60:2) coordinate(n+1) node[right]{$n+1$} -- (n);
    \draw ($ (one)!.25!(n) $) node[left]{$1'$} -- ($ (n+1)!.25!(n) $) node[above right]{$n+1'$} -- +(115:2) node[above]{$n+2$} -- (n);
  \end{tikzpicture}  
  
  Если $K(\bar{q}^{\,n+1}) > K(\bar{q}^{\,0})$, или если не получилось сжатие.\\
  Симплекс может быть неправильным.
  $$\bar{q}_{u'} = \bar{q}_u + \delta(\bar{q}_n - \bar{q}_u),\;\;\delta=0.4\div0.6$$
  Отражаем вершину $1'$ в мал. симплекс. Процесс заканчивается, когда размер симплекса значительно мал.
  
  \paragraph{Определение размера симплекса.}
  \begin{tikzpicture}
    \draw (0,0) node[below left]{0} -- (1,2) node[above]{$n$} -- (6,1) node[right]{1} -- (0,0) -- (1.5,1) -- (6,1);
    \draw (1.5,1) -- (1,2);
  \end{tikzpicture}
  
  Центр тяжести всех вершин:
  $$\bar{q}^{\,w,r} = \frac{1}{n+1}\sum_{u=0}^n \bar{q}^{\,u,r}$$
  Расстояние от вершины до центра тяжести:
  $$S_u^r = \left[ \sum_{u=1}^n \left(q_i^r - q_{iw}\right) \right]^{\sfrac{1}{2}}$$
  $$S^r = \frac{1}{n+1}\sum_{u=0}^n S_u^r$$
  $S^r \leq S_{\text{min}}$ --- процесс заканчивается $\Rightarrow$ берём либо оптимальную вершину, либо центр тяжести.\\
  
  \textbf{Преимущества:}
  \begin{itemize}
   \item[-] Эффективность. Близок к градиентному методу.
   \item[-] Учитывает ограничения. Если отражённая вершина за границей области наихудшая --- используется операция редукции.
  \end{itemize}
  
  \textbf{Недостатки:}
  \begin{itemize}
    \item[-] Локальный, а не глобальный экстремум.
    \item[-] Все вершины исходного многогранника должны лежать внутри допустимой области (за исключением одной).
  \end{itemize}
  Наиболее современный метод, наиболее универсальный.
  
  \section{Мультикритериальная оптимизация судовых технических систем.} %Multicriteria optimization
  Качество --- совокупность свойств системы, характеризующее её соответствие целевому назначению в заданных условиях функционирования.\\
  
  Критерий качества --- формализованное правило, позволяющее производить сравнительную оценку различных вариантов системы (решений) и выбирать оптимальную из них.\\
  
  Качество оценки с помощью показателей качества.\\
  Показатели:
  \begin{itemize}
    \item[-] Единичные --- содержат одно из свойств системы.
    \item[-] Комплексные --- совокупность свойств.
    \item[-] Обобщённые --- в целом качество системы.
  \end{itemize}
  
  Значение обобщённых показателей должно соответствовать степени соответствия целевому назначению.\\
  
  Имеется совокупность показателей, характеризующих систему. Должна обладать свойствами:
  \begin{enumerate}
   \item Должна быть презентативна (представительна), т.~e. всесторонне оценивать качество системы.
   \item Однозначность толкования\\
     Показатель должен характеризоваться числом.
   \item Управляемость.\\
     Меняя параметры менять значения показателя.
   \item Эффективна в статистическом смысле.\\
     Если показатель определяется статистическим испытанием --- оценки должны быть не смещённые.
   \item Все показатели измеряются в однородных шкалах.
  \end{enumerate}
  
  \paragraph{Нормирование (нормализация) показателей качества.}
  Существуют шкалы\\
  Качественные:
  \begin{enumerate}
    \item Классификационная шкала.
    Разбиение на классы (например, по наименованию).
    \item Порядковая шкала.
    В этом случае справедливо любое монотонное преобразование.
  \end{enumerate}
  Количественные:
  \begin{enumerate}
    \setcounter{enumi}{2}
    \item Интервальная шкала.\\
    $ax+b$ --- допустимое преобразование.\\
    $a$ --- масштаб, $b$ --- начало координат.
    \item Шкала отношений.\\
    масса, стоимость\\
    Чётко определено начало координат.\\
    $ax$\\
    Масштаб можем менять.
    \item Абсолютная шкала температур.
  \end{enumerate}
  
  У каждого показателя своя шкала отношений.\\
  От неоднородных шкал $\rightarrow$ к однородной шкале для всех показателей $\Rightarrow$ От отношений $\rightarrow$ к интервалам.\\
  
  Шкала интервалов: 0 $\div$ 1\\
  Допустим, максимизируемый показатель\\ 
  $K_{\rho\,max}$ --- превзойти невозможно или не имеет смысла.\\
  $K_{\rho\,min}$ --- меньше быть не может. 
  \[
    \left.
    \begin{aligned}
      &x_{\rho}=1 &\text{при}\quad &K_{\rho} \geq K_{\rho\,max}\\
      &x_{\rho}=0 &\text{при}\quad &K_{\rho} \leq K_{\rho\,min}\\
    \end{aligned}
    \quad\right\}
    \begin{aligned}
      &\text{линейные}\\
      &\text{преобразования}
    \end{aligned}
  \]
  
  \begin{tikzpicture}
    \draw[->] (0,0) node[below left]{0} -- (0,4) node[left]{$x$};
    \draw[->] (0,0) -- (9,0) node[below right]{$K_{\rho}$};    
    \draw[very thick] (0,0) -- (2,0) [name path=sloped] -- (7,3) -- (9,3);
    \draw[dashed] (0,3) node[left]{1} -- (7,3);
    \coordinate (a) at ($ (2,0)!.4!(7,3) $);
    \draw[dashed] (0,0 |- a) node[left]{$x$} -- (a);
    \draw[dashed] (a |- 0,0) node[below=2pt]{$K_0$} -- (a);
    
    \draw (2, 2pt) -- (2, -2pt) node[below]{$K_{\rho\,min}$};
    \draw (7, 2pt) -- (7, -2pt) node[below]{$K_{\rho\,max}$};
  \end{tikzpicture}
  
  $$x_{\rho} = \frac{K_{\rho}-K_{\rho\,min}}{K_{\rho\,max}-K_{\rho\,min}}$$
  $$a=\frac{1}{K_{\rho\,max}-K_{\rho\,min}}$$
  $$b=\frac{K_{\rho\,min}}{-K_{\rho\,max}-K_{\rho\,min}}$$
  
  \[
    \begin{aligned}
      &x_{\rho}=1 &K_{\rho} \leq K_{\rho\,max}\\
      &x_{\rho}=0 &K_{\rho} \geq K_{\rho\,min} &\quad \text{--- минимизируемый}
    \end{aligned}
  \]
  
  \begin{tikzpicture}
    \draw[->] (0,0) node[below left]{0} -- (0,4) node[left]{$x$};
    \draw[->] (0,0) -- (7,0) node[below right]{$K_{\rho}$};
    \draw (1,3) -- (6,0);
    \draw[dashed] (0,3) -- (7,3);
    \draw[dashed] (1,3) -- (1,0);
    \draw[dashed] ($ (1,3)!.5!(6,0) $) coordinate (a) -- (a |- 0,0);
    \draw (1, 2pt) -- (1, -2pt) node[below]{$K_{\rho\,min}$};
    \draw (6, 2pt) -- (6, -2pt) node[below]{$K_{\rho\,max}$};
  \end{tikzpicture}
  
  $$x_{\rho}=\frac{K_{\rho\,max}-K_{\rho}}{K_{\rho\,max}-K_{\rho\,min}}$$
  
  Могут быть логарифмические преобразования.\\
  
  Нормируемое значение показателя $x_{\rho}$ --- чем больше, тем лучше.
  
  \section{Критерии оптимальности (предпочтения)} %Optimality criterions
  
  %in progress,,,
  
  \section{Метод парных сравнений.} %Paired comparisons method

  $X_{\rho}$ и $X_{\xi}$ - показатели

  WTF?

  Матрица парных сравнений:

  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{Показ.} & \multicolumn{5}{c|}{Показатели}\\
    \cline{2-6}
    & 1 & 2 & \dots & $\xi$ & m\\
    \hline
    1 & --- & $\gamma_{12}$ & & $\gamma_{1\xi}$ & $\gamma_{1m}$\\
    \hline
    2 & $\gamma_{21}$ & --- & & $\gamma_{2\xi}$ & $\gamma_{2m}$\\
    \hline
    \vdots & & & & &\\
    \hline
    $\rho$ & $\gamma_{\rho 1}$ & $\gamma_{\rho 2}$ & \dots & $\gamma_{\rho\xi}$ & $\gamma_{\rho m}$\\
    \hline
    \vdots & & & & &\\
    \hline
    m & $\gamma_{m1}$ & $\gamma_{m2}$ & \dots & $\gamma_{m\xi}$ &\\
    \hline
  \end{tabular}

  $\gamma_{\rho wtf?} + \gamma_{wtf?\rho} = 1$ wtf?(обрезанно в PDF)

  $1 \succ 4 \succ 3 \succ 5 \succ 6$ - появление циклов

  $$\gamma_\rho = \sum_{\xi=1}^m\gamma_{\rho\xi}$$

  Чем больше $\gamma_\rho$, тем меньше ранг.

  \textbf{Примечание:}
  \begin{itemize}
    \item[-] При большем числе показателей более достоверные результаты.
    \item[-] Можно исключить плохо подготовленных экспертов.
  \end{itemize}

  \textbf{Пример:}

  1, 2, 3

  \begin{tabular}{c|c|c|c}
    & Н & Э & М-Г\\
    \hline
    Н & --- & 1 & 1\\
    М & 0 & --- & 1\\
    М-Г & 0 & 0 & ---
  \end{tabular}\\

  4, 5

  \begin{tabular}{c|c|c|c}
    & Н & Э & М-Г\\
    \hline
    Н & --- & 1 & 1\\
    М & 0 & --- & 0\\
    М-Г & 0 & 1 & ---
  \end{tabular}

  Суммарная таблица:

  \begin{tabular}{c|c|c|c|c}
    & Н & Э & М-Г & $\sum$\\
    \hline
    Н & --- & 5 & 5 & 10\\
    М & 0 & --- & 3 & 3\\
    М-Г & 0 & 2 & --- & 2
  \end{tabular}

  Сумма внедиагональных элементов соответствует матрице парных сравнений.

  \section{Для получения весовых коэффициентов: Метод непосредственной оценки.}

  Ранжирование уже произведено

  Каждый эксперт знает ранги, их точки зрения могут не совпадать.

  Надеж присвоенного значения 1:

  \begin{tabular}{c|c|c}
    Н & Э & М-Г\\
    \hline
    1 & 0.8 & 0.7\\
    1 & 0.9 & 0.6\\
    1 & 0.85 & 0.8\\
    1 & 0.6 & 0.8\\
    1 & 0.6 & 0.9
  \end{tabular}

  2 варианта нахождения среднего:
  \begin{enumerate}
    \item Средне арифметический.
    \item Расписать медиану:$$0.9 \ 0.85 \ \underbracket{0.8} \ 0.6 \ 0.6$$
  \end{enumerate}

  Если четное - 2 средних, нечетное - 1 среднее.

  Среднее арифметическое - 0.76, таким образом вычисляемые значения весового коэффициента, $\gamma$ потом нормируется чтобы в $\sum$ составлять 1.

  Выбор оптимальных решений в условиях неполной априорной информации. Любая система функций во внешней среде. Эта среда может существенно меняться, быть активной и пассивной.

  Активная - противодействие(явное): боевые действия, конкуренция.

  Теория игр - математическое описание ситуации, возникшей при активной внешней среде.

  Пассивная среда - нет уверенности, что она выберет wtf? состояние, но оно может быть.

  2 случая:
  \begin{enumerate}
    \item В условиях риска.
    \item В условиях неопределенности(любые внешние воздействия).
  \end{enumerate}

  \textbf{Пример:}

  Система управления курсом судна в открытом море.

  Волнения: 2, 3, 4 балла

  \begin{tabular}{c|c|c|cl}
    \cline{1-4}
    \multirow{2}{*}{Варианты} & \multicolumn{3}{c}{Волнения моря}&\\
    \cline{2-4}
    & 2 & 3 & 4&\\
    \cline{1-4}
    1 & 0.8 & 0.75 & 0.77&\\
    \cline{1-4}
    2 & 0.75 & 0.8 & 0.75&\\
    \cline{1-4}
    3 & 0.96 & 0.85 & 0.65&\\
    \cline{1-4}
    & 0.15 & 0.20 & 0.20 & - верность
  \end{tabular}

  Непрерывную ситуацию сводим к дискретной. Может быть сколь угодно состояний, так как высота волны непрерывна.

  Переходим к трём значениям:

  Задача. Рассмотри различные методы решения.

  3 события не предстовляют полную группу событий так как сумма их вероятностей не равна 1.

  Внешняя среда характеризуется ограниченным числом состояний.

  wtf?

  $X_{ur}$ - значение обобщается показателем $X$, соответствующее варианту $u$ в ситуации $r$.

  wtf?

  Если детерминированна задача, то матрица вырожена в первом столбце соответвенно заданному состоянию.

  \section{Отдельные состояния внешней среды-ситуации.}

  1. Критерий Байеса

  Основан на том, что известны вероятности отдельных ситуаций.

  Если все ситуации составляют полную группу событий, то:
  $$K_u = \sum_{r=1}^RK_{ur}P_r$$
  Если показатель максимизируемый, то:

  %To be continued...

\end{document}
