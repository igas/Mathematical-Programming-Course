\documentclass[12pt,a5paper]{scrbook}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage[a5paper]{geometry}
\geometry{left=2cm}
\geometry{right=1cm}
%\geometry{top=2cm}
%\geometry{bottom=2cm}

% newline after \paragraph
\makeatletter 
\renewcommand\paragraph{\@startsection{paragraph}{4}{0mm}% 
{-\baselineskip} % 
{0.5\baselineskip} % 
{\normalfont\bfseries}}% 
\makeatother 

\begin{document}
  \pagestyle{plain}
  \begin{titlepage}
    \newgeometry{left=1cm,right=1cm,top=3cm,bottom=1cm}
    \begin{center}
      \Huge{Ю.~Я.~Зубарев}
    \end{center}
    \vfill
    \vfill
    \begin{center}
      \Large{\textbf{Математическое программирование\\
      Конспект лекций}}
    \end{center}
    \vfill
    \vfill
    \vfill
    \restoregeometry
  \end{titlepage}
  \tableofcontents
  \newpage
  Математическое программирование - это методы принятия оптимальных решений.\par
  История развития методов математического программирования:
  \begin{enumerate}
    \item Системы автоматизации управления.\\Появились работы по оптимальным автоматическим системам.
    \item Методы, связанные с ракетной техникой.\\Решалась задача об оптимальной траектории ракет.
    \item Решение военных, экономических и административных задач.
    \item Логистика.
  \end{enumerate}\par
  Существовала и классическая теория оптимизации, но она не получила распространения, т.к. не учитывает ограничений.\par
  Критерий оптимальности - это формализованное правило, позволяющее производить сравнительную оценку различных вариантов (решений, процедур, операций...) и выбор наилучшей из них.\par
  Любая система (процесс, операция) характеризуется какими либо операциями.\par
\{СХЕМА!\}
  \begin{enumerate}
    \item Астрономические наблюдения.\\Судно - материальная точка.
    \item Волнения.\\Судно - линейная стохастическая модель.
    \item Разворот судна в порту.\\Нелинейная модель.
  \end{enumerate}\par
  Цель: свести решение задачи к типовым программным продуктам.\par
  Математическая формулировка задачи\par
  \(
  k(q_1, q_2\ldots q_n)\to min (max)
  \)
  \par
  3 показателя ограничений:\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\geq k_{\rho_{min}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\leq k_{\rho_{max}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n) = k_{\rho_{0}}
  \)\par
  $\rho = 1, 2, \ldots m$ (обычно затраты) применяется редко\par
  Рассмотрим 1й случай:\par
  $k$ - линейные функции от параметров $q$. В этом случае мы рассматриваем задачи линейного программирования.\par
  $k$ - нелинейные функции. Тогда мы рассматриваем задачи нелинейного программирования. Размерность задачи нелинейного программирования 2\,--\,5 параметров.\par
  $q$ - целочисленные, тогда имеем дело с целочисленным программированием (линейным и нелинейным). Разбиение задачи на подзадачи.\par
  Стохастическое программирование - нам не известны точные значения $q$, но известны их вероятностные характеристики или интервалы изменения их значений.\par
  \chapter{Методы одномерной оптимизации}
  \pagestyle{headings}
  $$k(q)\to min(max)$$\par
  Унимодальная функция\par
  \{ГРАФИК\}\par
  \section{Методы с последовательным уменьшением интервала неопределенности}
  $\Delta_0 = q_{max} - q_{min}$ -- это интервал неопределенности.\par
  Функция униполярная $\Rightarrow$ мы можем уменьшить интервал неопределенности.\par
  \{ГРАФИКИ\}\par
  Совершая различные вычисления, мы уменьшаем интервал неопределенности.
  \newpage
  \subsection{Метод дихотомии (деление пополам)}
  TODO: ГРАФИК
  \par
  Делим до тех пор, пока отрезок не будет достаточно мал.
  \par
  На каждой итерации 2 вычисления.
  \par
  $$\Delta_2 = \frac{\Delta_0}{2} + \frac{\varepsilon}{2}$$
  $$\Delta_4 = \frac{\Delta_0}{2^2} + \bigg(1 - \frac{1}{2^2}\bigg)\varepsilon$$
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}} + \bigg(\underbrace{1 - \frac{1}{2^{r/2}}}_{\rightarrow 1}\bigg)\varepsilon$$
  \par
  Если считать, что $\varepsilon$ можно пренебречь.
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}}$$
  \par
  Преимущество: Простота
  \par
  Недостаток: Плохая сходимость
  \subsection{Золотое сечение}
  Основан на следующий допущениях:
  \par
  $$\Delta_{r-1}, \Delta_r, \Delta_{r+1}$$
  \par
  \begin{enumerate}
    \item $\frac{\Delta_{r-1}}{\Delta_r} = \frac{\Delta_r}{\Delta_{r+1}} = \tau$
    \item $\Delta_{r-1} = \Delta_r + \Delta_{r+1}$
    TODO: заметка на поле
  \end{enumerate}
  $$\frac{\Delta_{r-1}}{\Delta_{r+1}} = \frac{\Delta_r}{\Delta_{r+1}} + 1$$
  $$\tau^\varrho = \tau + 1$$
  $$\tau = 1,618$$
  \par
  TODO: график
  \par
  На каждой итерации только одно вычисление, а на следующем берем результат предыдущего. На первой итерации 2 вычисления.
  $$\frac{\Delta_0}{\Delta_r} = \tau^{r-1}$$
  \par
  Преимущества: хорошая сходимость.
  \par
  Недостатки: достаточная сложность алгоритма.
  \section{Шаговые методы}
  При каждом последующем шаге результат должен быть не хуже предыдущего.
  \par
  \subsection{Метод с постоянным шагом}
  TODO: Графики
  $$k(q_2)>k(q_1)$$ TODO: график
  \subsection{Метод с переменным (пропорциональным) шагом}
  TODO: График
  $$q_3 = q_2 + \theta\frac{k(q_2) - k(q_1)}{\underbrace{q_2 - q_1}_{\lambda}}$$
  $$q^{(r)} = q^{(r-1)} + \theta = \frac{k(q^{r-1}) - k(q^{r+1})}{q^{(r+1)} - q^{(r-1)}}$$
  $$\theta = \frac{k(q^{(2)}) - k(q^{(1)})}{\lambda}$$
  $$\theta = \frac{\lambda^2}{k(q^{(2)}) - k(q^{(1)})}$$
  \par
  Частный случай градиентного метода. Шаг завичит от вида поверхности.
  \subsection{Метод с переменным шагом с последующей квадратичной апроксимацией}
  $$k = TODO: дописать функцию$$
  TODO: график
  \par
  Увеличиваем шаг в 2 раза, TODO: дописать параграф
  $$q^{r+1} = q^r + \lambda \cdot 2^{r-2}$$
  $$\lambda_1 = 2^{r-3}$$
  \par
  Отбрасываем одну из крайних точек, которая наихудшая.
  $$q_{max(min)} = q_0 + \frac{\lambda_1}{2} \cdot \frac{k(q_-) - k(q_+)}{k(q_-) - 2k(q_0) + k(q_+)}$$
  \par
  Подставим наши значения:
  $$q_{max} = 8 + \frac{4}{2} \cdot \frac{91 - 75}{91 - 2 \cdot 99 + 75} = 8 + 2 \cdot \frac{+16}{-32} = 7$$
  \par
  Порядок действий:
  \begin{enumerate}
    \item С каждым шагом величина шага увеличивается вдвое.
    \item Движение продолжается до тех пор пока значение $k$ не начнет уменьшаться.
    \item Берется половина последнего интервала и определяется значение показателя в дополнительной точке. Из рассматриваемых 4-х точек отбрасывается точка с наименьшим(наибольшим) значением.
    \item По формуле определяется $max(min)$ квадратичной зависимости, которая проходит через 3 оставшиеся точки.
    \item В случае необходимости уменьшают на порядок интервал и заново начинаем процедуру с полученной экстремальной точки.
  \end{enumerate}
  \chapter{Основы нелинейного программирования}
  Множество - это совокупность раздельных объектов, рассматриваемых в данной задаче как единое целое.
  \par
  Конечное множество имеет конечное количество элементов меньше натурального числа $N$.
  \par
  Если множество упорядочено - это картеж.
  \par
  $$
    q^{(1)} =
    \begin{bmatrix}
      q_{11}\\
      q_{12}\\
      \vdots
    \end{bmatrix}
  $$
  $$\bar{q}^{\,1T}$$
  \par
  Между точками можно совершать операции и выделять соотношения.
  \begin{enumerate}
    \item Расстояния\\$\bar{q}^{\,(1)}, \bar{q}^{\,(2)}, \bar{q}^{\,(3)}$
  \end{enumerate}
  \begin{enumerate}
    \item Аксиома идентичности\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = 0$
    \item Аксиома симметрии\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = (\bar{q}^{\,(2)}, \bar{q}^{\,(1)})$
    \item Аксиома треугольника\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(3)})\leq d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) + d(\bar{q}^{\,(2)}, \bar{q}^{\,(3)})$
  \end{enumerate}
  \par
  Если на множестве определены операции, то это множество обладает структурой (называют пространством)
  \par
  Если в пространство определяло расстояние (метрика), то пространство называют TODO.
  \par
  В судовых сетях прокладка кабеля осуществляется по Манхеттеновскому расстоянию.
  \par
  Евклидово расстояние:
  $$
    d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^2
      \right]^{\frac{1}{2}}
  $$
  \par
  Общая формула расстояния:
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^p
      \right]^{\frac{1}{p}},\; p \to \infty
  $$
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      = max
      \bigg[
        \Big(
          q_1^{(1)} - q_1^{(2)}
        \Big)
        \Big(
          q_2^{(1)} - q_2^{(2)}
        \Big)
        \ldots
        \Big(
          q_n^{(1)} - q_n^{(2)}
        \Big)
      \bigg]
  $$
  \par
  Бесконечное ограниченное множество
  \par
  $d\big(\bar{q}^{(1)}, \bar{q}^{(2)}\big) < M$, то множество бесконечно, но ограничено.
  \par
  Сфера:
  \par
  $d\big(\bar{q}, \bar{a}\big) = R$
  \par
  Шар:
  \par
  Замкнутый: $d\big(\bar{q}, \bar{a}\big) \leq R$
  \par
  Открытый: $d\big(\bar{q}, \bar{a}\big) < R$
  \par
  TODO: пятно
  \par
  Пусть $q_1, q_2\hspace{20pt} \lambda\bar{q}^{(1)} + (1 - \lambda)\bar{q}^{2(1)}$, то область называется выпуклой.
  \par
  Область называется замкнутой, если все граничные области принадлежат ей.
  \par
  Теорема Веерштрасса
  \par
  Если функция определена в замкнутом ограниченным и непустом множестве, то функция в этом множестве хотя бы один раз принимает $max$ и $min$ значения.
  \par
  Непустое множество - это множество содержащее хотябы одну точку.
  \par
  Экстремумы
  \par
  Где ищем экстремумы:
  TODO: какнибудь объеденить 1й и 2й пункт
  \begin{enumerate}
  	\item Стационарная точка.
  	\item Точка, где нет производной.
  	\item Граничные точки (условный экстремум).
  \end{enumerate}
  Классический метод оптимизации
  \par
  $$k(q_1, q_2, \ldots, q_r)$$
  \begin{enumerate}
  	\item Считается что функция гладкая и имеет в каждой точке 1ю и 2ю производные.
  	\item Не учитываем ограничения ни на $q$, ни на $k$.
  \end{enumerate}
  $$q^{0T} = \Big[q_1^0, q_2^0, \ldots, q_n^0\Big]$$
  $$k(\bar{q}) = k(\bar{q}^0_1) + \sum_{i = 1}^n\Bigg(\frac{\partial k}{\partial q_1}\Bigg)_0\Delta q_1 + \frac{1}{2}\sum^n_{i, j = 1}\Bigg(\frac{\partial^2 k}{\partial q_i\partial q_j}\Bigg)_0\Delta q_i\Delta q_j$$
  $$\Delta q_1 = q_{i_0} - q_1$$
  $$\Delta q_1 = q_{i_0} - q_j$$
  \par
  Если точка стационарная, то $\sum\Big(\frac{\partial k}{\partial q_i}\Big)_0 = 0$, тогда\\$k(q^0) - k(\bar{q}_1) = - \frac{1}{2}\sum_{i, j = 1}^n\Big(\frac{\partial^2k}{\partial q_i\partial q_j}\Big)_0 \Delta q_i\Delta q_j$
  \par
  Максимуму соответствует отрицательная квадратичная форма:
  $$\frac{\partial^2k}{\partial q_i q_j} = a_{ij}$$
  \par
  Введем матрицу Гессе:
  $$
  	\mathcal{J}(\bar{q}) =
  	\begin{bmatrix}
  	  a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
  	  a_{21} & a_{22} & a_{23} & \cdots & a_{2n}\\
  	  \vdots & \vdots & \vdots & \ddots & \vdots\\
  	  a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}\\
  	\end{bmatrix}
  $$
  \par
  Квадратическая форма
  $$\bar{q}^T\mathcal{J}(\bar{q})\bar{q}$$
  \par
  Необходимо определить свойства этой квадратичной формы. Рассмотрим определитель матрицы Гессе - гессиан.
  \par
  Критерий Сильвестра
  \par
  Если все ограничения положительны, то мы имеем положительную квадратичную форму, значит $min$.
  \par
  Если определители меняют знак (знакопеременные) то, тогда квадратичная форма отрицательная, следовательно мы имеем дело с $max$.
  \par
  Если не соблюдается ни первое, ни второе условия, такая точка - седло.
  \par
  Методом редко пользуются потому что:
  \begin{enumerate}
  	\item Слишком много допущений;
  	\item в аналитическом виде решение частных производных вычислить трудно, т.к. матрицу Гессе трудно определить.
  	\item не учитываются ограничения.
  \end{enumerate}
  \section{Метод множителей лагранжа}
  Допущения:
  \begin{enumerate}
  	\item Функция гладкая и в каждой точке имеет 1-ю и 2-ю производные.
  	\item $K_\rho = K_{\rho0}; \; \rho = 1,2,\ldots,m$  		
  \end{enumerate}
  $$L(\bar{q}) = K(\bar{q}) + \sum_{\rho=1}^{m} \lambda_\rho[K_{\rho_0} - K_\rho(\bar{q})]$$
  $$\frac{\partial L}{\partial q_i} = \frac{\partial K}{\partial q_i} - \sum_{\rho=1}^{m} \lambda_\rho \frac{\partial K_\rho(\bar{q})}{\partial q_i} = 0; \; i=1,2,\ldots,n$$
  $$\frac{\partial L}{\partial \lambda_\rho} = [K_{\rho_0} - K_\rho] = 0$$
  \paragraph*{Пример}
  $max P$ \\
  m - масса \\
  v - объём \\
  c - экономия \\
  $$max P$$
  $$m(v,c) \leq m(v_0,c_0)$$
  \begin{center}
	либо $min(m,v,c)$ при $P \geq P_0$
  \end{center}

  \section{Поисковые методы}
  Рассмотрим условия, когда локальный экстремум является глобальным. Рассмотрим понятия выпуклой и вогнутой функции.\\
  $$z = \lambda (K(\bar{q}') + (1-\lambda)K(\bar{q}''))$$  
  TODO: График;
  VERIFY  
  $$K[\lambda \bar{q}' + (1-\lambda+q'')] \leq Z = \lambda(K(\bar{q}' + (1-\lambda)K(\bar{q}'))$$
  Если знак неравенства $\leq$ - имеем дело с выпуклой функцией.\\
  Если неравенство строгое - строго выпуклая функция.\\
  Если знак $\geq$ - то функция вогнутая.\\
  
  Если на выпуклом множестве определена вогнутая функция, тогда локальный максимум является глобальным.
  
  \section{Метод Гаусса-Зейделя}
  Функция $K(q_1, q_2, \ldots, q_n)$ \\
  $q_1, q_2, \ldots, q_n = const $
  \begin{enumerate}
    \item $max(min(K(q_1)))$ \\
      TODO График:
    \item $min(max(K(q_1)))$ \\
      TODO График:
  \end{enumerate}
  $$|q_1^m - q_1^r| \leq \epsilon_i - q_n$$
  $$|K^m - K^r| \leq \eta $$
\end{document}
