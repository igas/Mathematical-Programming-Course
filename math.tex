\documentclass[14pt,a5paper]{book}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage[a5paper]{geometry}
\geometry{left=2cm}
\geometry{right=1cm}
\geometry{top=2cm}
\geometry{bottom=2cm}
\begin{document}
  \begin{titlepage}
    \newgeometry{left=1cm,right=1cm,top=3cm,bottom=1cm}
    \begin{center}
      \Huge{Ю.~Я.~Зубарев}
    \end{center}
    \vfill
    \vfill
    \begin{center}
      \Large{\textbf{Математическое программирование\\
      Конспект лекций}}
    \end{center}
    \vfill
    \vfill
    \vfill
    \restoregeometry
  \end{titlepage}
  \tableofcontents
  \newpage
  Математическое программирование - это методы принятия оптимальных решений.\par
  История развития методов математического программирования:
  \begin{enumerate}
    \item Системы автоматизации управления.\\Появились работы по оптимальным автоматическим системам.
    \item Методы, связанные с ракетной техникой.\\Решалась задача об оптимальной траектории ракет.
    \item Решение военных, экономических и административных задач.
    \item Логистика.
  \end{enumerate}\par
  Существовала и классическая теория оптимизации, но она не получила распространения, т.к. не учитывает ограничений.\par
  Критерий оптимальности - это формализованное правило, позволяющее производить сравнительную оценку различных вариантов (решений, процедур, операций...) и выбор наилучшей из них.\par
  Любая система (процесс, операция) характеризуется какими либо операциями.\par
\{СХЕМА!\}
  \begin{enumerate}
    \item Астрономические наблюдения.\\Судно - материальная точка.
    \item Волнения.\\Судно - линейная стохастическая модель.
    \item Разворот судна в порту.\\Нелинейная модель.
  \end{enumerate}\par
  Цель: свести решение задачи к типовым программным продуктам.\par
  Математическая формулировка задачи\par
  \(
  k(q_1, q_2\ldots q_n)\to min (max)
  \)
  \par
  3 показателя ограничений:\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\geq k_{\rho_{min}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\leq k_{\rho_{max}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n) = k_{\rho_{0}}
  \)\par
  $\rho = 1, 2, \ldots m$ (обычно затраты) применяется редко\par
  Рассмотрим 1й случай:\par
  $k$ - линейные функции от параметров $q$. В этом случае мы рассматриваем задачи линейного программирования.\par
  $k$ - нелинейные функции. Тогда мы рассматриваем задачи нелинейного программирования. Размерность задачи нелинейного программирования 2\,--\,5 параметров.\par
  $q$ - целочисленные, тогда имеем дело с целочисленным программированием (линейным и нелинейным). Разбиение задачи на подзадачи.\par
  Стохастическое программирование - нам не известны точные значения $q$, но известны их вероятностные характеристики или интервалы изменения их значений.\par
  \chapter{Методы одномерной оптимизации}
  $$k(q)\to min(max)$$\par
  Унимодальная функция\par
  \{ГРАФИК\}\par
  \section{Методы с последовательным уменьшением интервала неопределенности}
  $\Delta_0 = q_{max} - q_{min}$ -- это интервал неопределенности.\par
  Функция униполярная $\Rightarrow$ мы можем уменьшить интервал неопределенности.\par
  \{ГРАФИКИ\}\par
  Совершая различные вычисления, мы уменьшаем интервал неопределенности.
  \newpage
  \subsection{Метод дихотомии (деление пополам)}
  TODO: ГРАФИК
  \par
  Делим до тех пор, пока отрезок не будет достаточно мал.
  \par
  На каждой итерации 2 вычисления.
  \par
  $$\Delta_2 = \frac{\Delta_0}{2} + \frac{\varepsilon}{2}$$
  $$\Delta_4 = \frac{\Delta_0}{2^2} + \bigg(1 - \frac{1}{2^2}\bigg)\varepsilon$$
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}} + \bigg(\underbrace{1 - \frac{1}{2^{r/2}}}_{\rightarrow 1}\bigg)\varepsilon$$
  \par
  Если считать, что $\varepsilon$ можно пренебречь.
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}}$$
  \par
  Преимущество: Простота
  \par
  Недостаток: Плохая сходимость
  \subsection{Золотое сечение}
  Основан на следующий допущениях:
  \par
  $$\Delta_{r-1}, \Delta_r, \Delta_{r+1}$$
  \par
  \begin{enumerate}
    \item $\frac{\Delta_{r-1}}{\Delta_r} = \frac{\Delta_r}{\Delta_{r+1}} = \tau$
    \item $\Delta_{r-1} = \Delta_r + \Delta_{r+1}$
    TODO: заметка на поле
  \end{enumerate}
  $$\frac{\Delta_{r-1}}{\Delta_{r+1}} = \frac{\Delta_r}{\Delta_{r+1}} + 1$$
  $$\tau^\varrho = \tau + 1$$
  $$\tau = 1,618$$
  \par
  TODO: график
  \par
  На каждой итерации только одно вычисление, а на следующем берем результат предыдущего. На первой итерации 2 вычисления.
  $$\frac{\Delta_0}{\Delta_r} = \tau^{r-1}$$
  \par
  Преимущества: хорошая сходимость.
  \par
  Недостатки: достаточная сложность алгоритма.
  \section{Шаговые методы}
  При каждом последующем шаге результат должен быть не хуже предыдущего.
  \par
  \subsection{Метод с постоянным шагом}
  TODO: Графики
  $$k(q_2)>k(q_1)$$ TODO: график
  \subsection{Метод с переменным (пропорциональным) шагом}
  TODO: График
  $$q_3 = q_2 + \theta\frac{k(q_2) - k(q_1)}{\underbrace{q_2 - q_1}_{\lambda}}$$
  $$q^{(r)} = q^{(r-1)} + \theta = \frac{k(q^{r-1}) - k(q^{r+1})}{q^{(r+1)} - q^{(r-1)}}$$
  $$\theta = \frac{k(q^{(2)}) - k(q^{(1)})}{\lambda}$$
  $$\theta = \frac{\lambda^2}{k(q^{(2)}) - k(q^{(1)})}$$
  \par
  Частный случай градиентного метода. Шаг завичит от вида поверхности.
  \subsection{Метод с переменным шагом с последующей квадратичной апроксимацией}
  $$k = TODO: дописать функцию$$
  TODO: график
  \par
  Увеличиваем шаг в 2 раза, TODO: дописать параграф
  $$q^{r+1} = q^r + \lambda \cdot 2^{r-2}$$
  $$\lambda_1 = 2^{r-3}$$
  \par
  Отбрасываем одну из крайних точек, которая наихудшая.
  $$q_{max(min)} = q_0 + \frac{\lambda_1}{2} \cdot \frac{k(q_-) - k(q_+)}{k(q_-) - 2k(q_0) + k(q_+)}$$
  \par
  Подставим наши значения:
  $$q_{max} = 8 + \frac{4}{2} \cdot \frac{91 - 75}{91 - 2 \cdot 99 + 75} = 8 + 2 \cdot \frac{+16}{-32} = 7$$
  \par
  Порядок действий:
  \begin{enumerate}
    \item С каждым шагом величина шага увеличивается вдвое.
    \item Движение продолжается до тех пор пока значение $k$ не начнет уменьшаться.
    \item Берется половина последнего интервала и определяется значение показателя в дополнительной точке. Из рассматриваемых 4-х точек отбрасывается точка с наименьшим(наибольшим) значением.
    \item По формуле определяется $max(min)$ квадратичной зависимости, которая проходит через 3 оставшиеся точки.
    \item В случае необходимости уменьшают на порядок интервал и заново начинаем процедуру с полученной экстремальной точки.
  \end{enumerate}
  \newpage
  \begin{equation} \label{eq:someequation}
    \bar{q}^{\,r+1}=\bar{q}^{\,r}-\theta J^{\,-1}(q^{\,r})\nabla K(\bar{q}^{\,r})
  \end{equation}
В частном случае
\end{document}
