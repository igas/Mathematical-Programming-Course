\documentclass[12pt,a5paper]{scrbook}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{xfrac}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{decorations.pathreplacing}
\usepgflibrary{shapes.misc}
\usetikzlibrary{intersections}
%\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[a5paper]{geometry}
\geometry{left=2.5cm}
\geometry{right=1.5cm}
\geometry{top=2cm}
\geometry{bottom=3cm}

% newline after \paragraph
\makeatletter 
\renewcommand\paragraph{\@startsection{paragraph}{4}{0mm}% 
{-\baselineskip} % 
{0.5\baselineskip} % 
{\normalfont\bfseries}}% 
\makeatother 

\begin{document}
  \pagestyle{plain}
  \begin{titlepage}
    \newgeometry{left=1cm,right=1cm,top=3cm,bottom=1cm}
    \begin{center}
      \Huge{Ю.~Я.~Зубарев}
    \end{center}
    \vfill
    \vfill
    \begin{center}
      \Large{\textbf{Математическое программирование\\
      Конспект лекций}}
    \end{center}
    \vfill
    \vfill
    \vfill
    \restoregeometry
  \end{titlepage}
  \tableofcontents
  \newpage
  Математическое программирование - это методы принятия оптимальных решений.\par
  История развития методов математического программирования:
  \begin{enumerate}
    \item Системы автоматизации управления.\\Появились работы по оптимальным автоматическим системам.
    \item Методы, связанные с ракетной техникой.\\Решалась задача об оптимальной траектории ракет.
    \item Решение военных, экономических и административных задач.
    \item Логистика.
  \end{enumerate}\par
  Существовала и классическая теория оптимизации, но она не получила распространения, т.к. не учитывает ограничений.\par
  Критерий оптимальности - это формализованное правило, позволяющее производить сравнительную оценку различных вариантов (решений, процедур, операций...) и выбор наилучшей из них.\par
  Любая система (процесс, операция) характеризуется какими либо операциями.\par
\{СХЕМА!\}
  \begin{enumerate}
    \item Астрономические наблюдения.\\Судно - материальная точка.
    \item Волнения.\\Судно - линейная стохастическая модель.
    \item Разворот судна в порту.\\Нелинейная модель.
  \end{enumerate}\par
  Цель: свести решение задачи к типовым программным продуктам.\par
  Математическая формулировка задачи\par
  \(
  k(q_1, q_2\ldots q_n)\to min (max)
  \)
  \par
  3 показателя ограничений:\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\geq k_{\rho_{min}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n)\leq k_{\rho_{max}}
  \)\par
  \(
  k_{\rho}(q_1, q_2\ldots q_n) = k_{\rho_{0}}
  \)\par
  $\rho = 1, 2, \ldots m$ (обычно затраты) применяется редко\par
  Рассмотрим 1й случай:\par
  $k$ - линейные функции от параметров $q$. В этом случае мы рассматриваем задачи линейного программирования.\par
  $k$ - нелинейные функции. Тогда мы рассматриваем задачи нелинейного программирования. Размерность задачи нелинейного программирования 2\,--\,5 параметров.\par
  $q$ - целочисленные, тогда имеем дело с целочисленным программированием (линейным и нелинейным). Разбиение задачи на подзадачи.\par
  Стохастическое программирование - нам не известны точные значения $q$, но известны их вероятностные характеристики или интервалы изменения их значений.\par
  \chapter{Методы одномерной оптимизации}
  \pagestyle{headings}
  $$k(q)\to min(max)$$
  $$q_{min}\leq q \leq q_{max}$$
  Унимодальная функция
  \begin{figure}[h]
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[anchor=north] {};
    \draw[->] (0,-0.5)--(0,3.5) node[anchor=east] {};
    \draw (1,0) node[below]{$q_{min}$} .. controls (1.5,4) and (4.5,4) .. (5,0) node[below]{$q_{max}$};
    \draw[dashed] (3,0) node[below]{$q_0$} -- (3,3);
  \end{tikzpicture}
  \end{figure}
  \section{Методы с последовательным уменьшением интервала неопределенности}
  $\Delta_0 = q_{max} - q_{min}$ -- это интервал неопределенности.\par
  Функция униполярная $\Rightarrow$ мы можем уменьшить интервал неопределенности.
  \begin{center}
  \begin{tabular}{lcr}
  \begin{tikzpicture}[scale=0.5]
    \draw (0,0) -- (9,0);
    \draw (3,0) -- (3,1);
    \draw (6,0) -- (6,2);
    \draw[dashed] (3,0) -- (3,-1);
    \draw[dashed] (9,0) -- (9,-1);
    \draw[<->] (3,-1) -- (9,-1);
  \end{tikzpicture}
  &
  или
  &
  \begin{tikzpicture}[scale=0.5]
    \draw (0,0) -- (9,0);
    \draw (3,0) -- (3,2);
    \draw (6,0) -- (6,1);
    \draw[dashed] (0,0) -- (0,-1);
    \draw[dashed] (6,0) -- (6,-1);
    \draw[<->] (0,-1) -- (6,-1);
  \end{tikzpicture}
  \end{tabular}
  \end{center}
  \par
  Совершая различные вычисления, мы уменьшаем интервал неопределенности.
  \newpage
  \subsection{Метод дихотомии (деление пополам)}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (5,0);
    \draw (2,0) -- (2,0.75);
    \draw (3,0) -- (3,1.25);
    \draw (2.5,-0.05) -- (2.5,0.05);
    \draw[decorate,decoration=brace] (3,0) -- (2,0);
    \draw (2.5,0) node[below] {$\varepsilon$};
    \draw[decorate,decoration=brace] (2,0) -- (2.5,0);
    \draw (2.25,0.75) node[below] {$\sfrac{\varepsilon}{2}$};
    \draw[decorate,decoration=brace] (2.5,0) -- (3,0);
    \draw (2.75,0.75) node[below] {$\sfrac{\varepsilon}{2}$};
    \draw[|-|] (2,-0.75) -- (5,-0.75);
    \draw (3.25,-0.75) -- (3.25,-0.55);
    \draw (3.75,-0.75) -- (3.75,-0.35);
    \draw[|-|] (2,-1.5) -- (3.75,-1.5);
    \draw[dashed] (2,-1.5) -- (2,0);
    \draw[dashed] (5,0) -- (5,-0.75);
    \draw[dashed] (3.75,-1.5) -- (3.75,-0.75);
  \end{tikzpicture}
  \par
  Делим до тех пор, пока отрезок не будет достаточно мал.
  \par
  На каждой итерации 2 вычисления.
  \par
  $$\Delta_2 = \frac{\Delta_0}{2} + \frac{\varepsilon}{2}$$
  $$\Delta_4 = \frac{\Delta_0}{2^2} + \bigg(1 - \frac{1}{2^2}\bigg)\varepsilon$$
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}} + \bigg(\underbrace{1 - \frac{1}{2^{r/2}}}_{\rightarrow 1}\bigg)\varepsilon$$
  \par
  Если считать, что $\varepsilon$ можно пренебречь.
  $$\Delta_r = \frac{\Delta_0}{2^{r/2}}$$
  \par
  Преимущество: Простота
  \par
  Недостаток: Плохая сходимость
  \subsection{Золотое сечение}
  Основан на следующий допущениях:
  \par
  $$\Delta_{r-1}, \Delta_r, \Delta_{r+1}$$
  \par
  \begin{enumerate}
    \item $\frac{\Delta_{r-1}}{\Delta_r} = \frac{\Delta_r}{\Delta_{r+1}} = \tau$
    \item $\Delta_{r-1} = \Delta_r + \Delta_{r+1}$\qquad /$:\Delta_{r+1}$
  \end{enumerate}
  $$\frac{\Delta_{r-1}}{\Delta_{r+1}} = \frac{\Delta_r}{\Delta_{r+1}} + 1$$
  $$\tau^\varrho = \tau + 1$$
  $$\tau = 1,618$$
  \par
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (3,0);
    \draw (1,0) -- (1,1);
    \draw (2,0) -- (2,0.5);
    \draw[decorate,decoration={brace,raise=3pt}] (1.5,0) -- (0,0);
    \draw[decorate,decoration={brace,raise=3pt}] (3,0) -- (1.5,0);
    \draw (0.75,-0.1) node[below] {$\frac{\Delta_0}{\tau}$};
    \draw (2.25,-0.1) node[below] {$\frac{\Delta_0}{\tau}$};
    \draw (0.5,-0.9) node[below] {$\frac{\Delta_0}{\tau^{\,2}}$};
    \draw (0.5,-0.9) node[below] {$\frac{\Delta_0}{\tau^{\,2}}$};
    \draw[<->] (0,-0.9) -- (1,-0.9);
    \draw[dashed] (1,-0.9) -- (1,0);
    \draw[dashed] (0,-0.9) -- (0,0);
  \end{tikzpicture}
  \par
  На каждой итерации только одно вычисление, а на следующем берем результат предыдущего. На первой итерации 2 вычисления.
  \par
  $r$ - вычислений
  \par
  $(r-1)$ - итерация
  $$\frac{\Delta_0}{\Delta_r} = \tau^{r-1}$$
  \par
  Преимущества: хорошая сходимость.
  \par
  Недостатки: достаточная сложность алгоритма.
  \section{Шаговые методы}
  При каждом последующем шаге результат должен быть не хуже предыдущего.
  \par
  \subsection{Метод с постоянным шагом}
  \begin{center}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (5,0);
    \draw (1,0) -- (1,0.25);
    \draw (2,0) -- (2,0.5);
    \draw (1,0) node[below] {$q^{\,(1)}$};
    \draw (2,0) node[below] {$q^{\,(2)}$};
    \draw (1.5,0) node[above] {$\lambda$};
  \end{tikzpicture}
  \end{center}
  $$k\Big(q^{\,(2)}\Big)>k\Big(q^{\,(1)}\Big)\text{\;--\;вправо}$$
  $$k\Big(q^{\,(2)}\Big)<k\Big(q^{\,(1)}\Big)\text{\;--\;влево}$$
  $$k\big(q^{\,r+1}\big)<k\big(q^{\,r}\big)$$
  \begin{center}
  \begin{tikzpicture}
    \draw[|-|] (0,0) -- (2,0);
    \draw (1,0) node[below] {$\lambda = \lambda'm$};
    \draw (0,0) node[above] {$\lambda_r$};
    \draw (2,0) node[above] {$\lambda_{r+1}$};
  \end{tikzpicture}
  \end{center}
  \subsection{Метод с переменным (пропорциональным) шагом}
  TODO: График??????
  $$q^{\,(3)} = q^{\,(2)} + \Theta\frac{k(q^{\,(2)}) - k(q^{\,(1)})}{\underbrace{q^{\,(2)} - q^{\,(1)}}_{\lambda}}$$
  $$q^{(r)} = q^{(r-1)} + \Theta = \frac{k(q^{r-1}) - k(q^{r-2})}{q^{(r-1)} - q^{(r-2)}}=\frac{k(q^{r-1}) - k(q^{r-2})}{\lambda}$$
  $$\Theta\frac{k\Big(q^{(2)}\Big) - k\Big(q^{(1)}\Big)}{\lambda}=\lambda$$
  $$\Theta = \frac{\lambda^2}{k(q^{(2)}) - k(q^{(1)})}$$
  \par
  Частный случай градиентного метода. Шаг зависит от вида поверхности.
  \subsection{Метод с переменным шагом с последующей квадратичной апроксимацией}
  $$k = TODO: дописать функцию$$
  TODO: график
  \par
  Увеличиваем шаг в 2 раза, TODO: дописать параграф
  $$q^{r+1} = q^r + \lambda \cdot 2^{r-2}$$
  $$\lambda_1 = 2^{r-3}$$
  \par
  Отбрасываем одну из крайних точек, которая наихудшая.
  $$q_{max(min)} = q_0 + \frac{\lambda_1}{2} \cdot \frac{k(q_-) - k(q_+)}{k(q_-) - 2k(q_0) + k(q_+)}$$
  \par
  Подставим наши значения:
  $$q_{max} = 8 + \frac{4}{2} \cdot \frac{91 - 75}{91 - 2 \cdot 99 + 75} = 8 + 2 \cdot \frac{+16}{-32} = 7$$
  \par
  Порядок действий:
  \begin{enumerate}
    \item С каждым шагом величина шага увеличивается вдвое.
    \item Движение продолжается до тех пор пока значение $k$ не начнет уменьшаться.
    \item Берется половина последнего интервала и определяется значение показателя в дополнительной точке. Из рассматриваемых 4-х точек отбрасывается точка с наименьшим(наибольшим) значением.
    \item По формуле определяется $max(min)$ квадратичной зависимости, которая проходит через 3 оставшиеся точки.
    \item В случае необходимости уменьшают на порядок интервал и заново начинаем процедуру с полученной экстремальной точки.
  \end{enumerate}
  \chapter{Основы нелинейного программирования}
  Множество - это совокупность раздельных объектов, рассматриваемых в данной задаче как единое целое.\par
  Конечное множество имеет конечное количество элементов меньше натурального числа $N$.\par
  Если множество упорядочено - это кортеж. Любая точка рассматривается как вектор.
  $$
    q^{(1)} =
    \begin{bmatrix}
      q_{11}\\
      q_{12}\\
      \vdots
    \end{bmatrix}
  $$
  $$\bar{q}^{\,1T}$$
  \par
  Между точками можно совершать операции и выделять соотношения.\par
  Есть 3 точки: $\bar{q}^{\,(1)}, \bar{q}^{\,(2)}, \bar{q}^{\,(3)}$
  \begin{enumerate}
    \item Аксиома идентичности\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = 0$
    \item Аксиома симметрии\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) = (\bar{q}^{\,(2)}, \bar{q}^{\,(1)})$
    \item Аксиома треугольника\\$d(\bar{q}^{\,(1)}, \bar{q}^{\,(3)})\leq d(\bar{q}^{\,(1)}, \bar{q}^{\,(2)}) + d(\bar{q}^{\,(2)}, \bar{q}^{\,(3)})$
  \end{enumerate}
  \par
  Если на множестве определены операции, то это множество обладает структурой (называют пространством)\par
  Если в пространство определяло расстояние (метрика), то пространство называют метрическим.
  
  \paragraph{Манхеттоновское расстояние}
  В судовых сетях прокладка кабеля осуществляется по манхеттеновскому расстоянию.
  $$d \left( \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)} \right) = \sum_{i=1}^n |\bar{q}_i^{\,\left(1\right)} - \bar{q}_i^{\,\left(2\right)}|$$
  
  \paragraph{Евклидово расстояние}
  $$
    d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^2
      \right]^{\frac{1}{2}}
  $$
  \par
  Общая формула расстояния:
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      =
      \left[
        \sum_{i = 1}^{n}
        \left[
          q^{(1)}_{i} - q^{(2)}
        \right]^p
      \right]^{\frac{1}{p}}
  $$
  \par
  Если $p \to \infty$,
  $$
  	d
      \Big(
        \bar{q}^{\,\left(1\right)}, \bar{q}^{\,\left(2\right)}
      \Big)
      = max
      \bigg[
        \Big(
          q_1^{(1)} - q_1^{(2)}
        \Big)
        \Big(
          q_2^{(1)} - q_2^{(2)}
        \Big)
        \ldots
        \Big(
          q_n^{(1)} - q_n^{(2)}
        \Big)
      \bigg]
  $$

  \paragraph{Бесконечное ограниченное множество}
  $d\big(\bar{q}^{(1)}, \bar{q}^{(2)}\big) < M$, то множество бесконечно, но ограничено.
  \begin{wrapfigure}{r}{3cm}
  \begin{tikzpicture}[scale=1.4]
    \draw (2,2) .. controls +(0,1) and +(-0.25,0.25) .. (3,3.5)
  				.. controls +(0.3,-0.2) and +(0.5,1) .. (3.5,2.5)
  				.. controls +(-0.2,-0.5) and +(0,-0.3) .. (2,2);
    \filldraw (2.5,2.3) circle (1pt) node[anchor=west] {$q_1$};  	
  	\filldraw (3,3) circle (1pt) node[anchor=west] {$q_2$};
  \end{tikzpicture}
  \end{wrapfigure}
  Сфера: \par
  $d\big(\bar{q}, \bar{a}\big) = R$\\
  Шар:\par
  Замкнутый: $d\big(\bar{q}, \bar{a}\big) \leq R$\par
  Открытый: $d\big(\bar{q}, \bar{a}\big) < R$\\
  Если все точки шара принадлежат точкам шара, то точка называется внутренней. Если некоторые области находятся вне шара, то она называется граничной.
  
  \paragraph{Выпуклые области}
  Пусть существуют $\bar{q}^{\,(1)}, \bar{q}^{\,(2)}$\,, и если $\lambda\bar{q}^{(1)} + (1 - \lambda)\bar{q}^{(2)} \in \Theta$, то область называется выпуклой.
  \par
  Область называется замкнутой, если все граничные области принадлежат ей.

  \paragraph{Теорема Вейерштрасса}
  Если функция определена в замкнутом ограниченном и непустом множестве (\textsc{зона}), то функция в этом множестве хотя бы один раз принимает $max$ и $min$ значения.
  \par
  Непустое множество - это множество содержащее хотябы одну точку.
  
  \paragraph{Рассмотрим виды экстремумов}
  TODO: График\\
  \begin{tikzpicture}
    \clip (-1,-1) rectangle (10,7);
    \draw[->] (-0.5,0)--(9,0) node[anchor=north] {$q$};
  	\draw[->] (0,-0.5)--(0,6) node[anchor=east] {$k$};
  	\coordinate (a2) at (1,1);
  	\coordinate (a1) at (2,5);
  	\coordinate (a4) at (3,2);
  	\coordinate (a5) at (4,2);
  	\coordinate (a6) at (5,2);
  	\coordinate (a3) at (6,3.5);
  	\coordinate (x) at (7,1.5);
  	% dots
  	\filldraw ($(a2) +(.05,-.03)$) circle (1pt) node[right=3pt] {2};
  	\filldraw ($(a1) +(.2,.03)$) circle (1pt) node[above] {1};
  	\filldraw (a4) circle (1pt) node[below] {4};
  	\filldraw ($(a5) +(0,-.08)$) circle (1pt) node[below] {5};
  	\filldraw (a6) circle (1pt) node[below] {6};
  	\filldraw (a3) circle (1pt) node[above] {3};
  	% curve
  	\draw[name path=first curve] (0.5,6) .. controls ($(a2) +(0,-8)$) and ($(a1) +(0,5)$) .. (2.5,3.5);
  	\draw (2.5,3.5) ..controls ($(a4) +(-0.3,0.1)$) .. (a4);
  	\draw (a4) .. controls ($(a5) +(0,-.1)$) .. (a6);
  	\draw (a6) .. controls ($(a6) +(.3,.1)$) .. (5.5,3);
  	\draw (5.5,3) .. controls ($(a3) +(-.4,-.2)$) and ($(a3) +(-.2,0)$) .. (a3);
  	\draw (a3) .. controls ($(a3) +(.2,0)$) and ($(a3) +(.4,-.1)$) .. (6.5,3);
  	\draw (6.5,3) .. controls ($(x) +(-.2,.1)$) .. (x);
  	\draw[name path=last curve] (x) .. controls ($(x) +(0.3,0)$) .. (8,5);
  	% help lines
  	\draw[dashed] (1.05,0) node[below] {$q_{min}$} -- (1.05,6);
  	\draw[dashed,name path=help line] (7.5,0) node[below] {$q_{max}$} -- (7.5,6);
  	\fill [name intersections={of=last curve and help line, by={a7}}]
  	  (a7) circle (1pt) node[right] {7};
  \end{tikzpicture}\\
  Глобальный сильный максимум (1)
  $$k(\bar{q}_0) > k(\bar{q});\, q \in \Theta$$
  Глобальный сильный минимум (2)
  $$k(\bar{q}_0) < k(\bar{q});\, q \in \Theta$$
  Локальный сильный максимум (3)
  $$k(\bar{q}_0) < k(\bar{q});\, q_0 \in \Theta$$
  Локальный слабый минимум (4,5,6)
  $$k(\bar{q}_0) \geq k(\bar{q});\, q_0 \in \Theta$$
  Условный экстремум - точки лежащие на границе (2,7).\\
  Безусловный экстремум - точки лежащие внутри области.\par
  Где ищем экстремумы:
  \begin{enumerate}
  	\item Стационарные точки - точки, где экстремум равен нулю (безусловный экстремум).
  	\item Безусловный экстремум (точки, где нет производных).
  	\item Граничные точки (условный экстремум).
  \end{enumerate}
  
  \section{Классический метод оптимизации}
  $$k(q_1, q_2, \ldots, q_r)$$
  \begin{enumerate}
  	\item Считается что функция гладкая и имеет в каждой точке 1ю и 2ю производные.
  	\item Не учитываем ограничения ни на $q$, ни на $k$.
  \end{enumerate}
  $$q^{0T} = \Big[q_1^0, q_2^0, \ldots, q_n^0\Big]$$
  $$k(\bar{q}) = k(\bar{q}^0) + \sum_{i = 1}^n\Bigg(\frac{\partial k}{\partial q_i}\Bigg)_0\Delta q_i + \frac{1}{2}\sum^n_{i, j = 1}\Bigg(\frac{\partial^2 k}{\partial q_i\partial q_j}\Bigg)_0\Delta q_i\Delta q_j$$
  $$\Delta q_i = q_{i_0} - q_i$$
  $$\Delta q_j = q_{i_0} - q_j$$
  \par
  Если точка стационарная, то $\sum\Big(\frac{\partial k}{\partial q_i}\Big)_0 = 0$, тогда
  $$k(q^0) - k(\bar{q}_1) = - \frac{1}{2}\sum_{i, j = 1}^n\left(\frac{\partial^2k}{\partial q_i\partial q_j}\right)_0 \Delta q_i\Delta q_j$$
  \par
  Максимуму соответствует отрицательная квадратичная форма:
  $$\frac{\partial^2k}{\partial q_i q_j} = a_{ij}$$
  \par
  Введем матрицу Гессе:
  $$
  	\mathcal{J}(\bar{q}) =
  	\begin{bmatrix}
  	  a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
  	  a_{21} & a_{22} & a_{23} & \cdots & a_{2n}\\
  	  \vdots & \vdots & \vdots & \ddots & \vdots\\
  	  a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}\\
  	\end{bmatrix}
  $$
  \par
  Квадратическая форма
  $$\bar{q}^T\mathcal{J}(\bar{q})\bar{q}$$
  \par
  Необходимо определить свойства этой квадратичной формы. Рассмотрим определитель матрицы Гессе - гессиан.
  \paragraph{Критерий Сильвестра}
  Если все ограничения положительны, то мы имеем положительную квадратичную форму, значит $min$.
  \par
  Если определители меняют знак (знакопеременные) то, тогда квадратичная форма отрицательная, следовательно мы имеем дело с $max$.
  \par
  Если не соблюдается ни первое, ни второе условия, такая точка - седло.
  \par
  Методом редко пользуются потому что:
  \begin{enumerate}
  	\item Слишком много допущений;
  	\item в аналитическом виде решение частных производных вычислить трудно, т.к. матрицу Гессе трудно определить.
  	\item не учитываются ограничения.
  \end{enumerate}
  \section{Метод множителей лагранжа}
  Допущения:
  \begin{enumerate}
  	\item Функция гладкая и в каждой точке имеет 1-ю и 2-ю производные.
  	\item $k_\rho = k_{\rho0}; \; \rho = 1,2,\ldots,m$  		
  \end{enumerate}
  $$L(\bar{q}) = k(\bar{q}) + \sum_{\rho=1}^{m} \lambda_\rho[k_{\rho_0} - k_\rho(\bar{q})]$$
  $\lambda_\rho$ --- множитель Лагранжа.
  $$\frac{\partial L}{\partial q_i} = \frac{\partial k}{\partial q_i} - \sum_{\rho=1}^{m} \lambda_\rho \frac{\partial k_\rho(\bar{q})}{\partial q_i} = 0; \; i=1,2,\ldots,n$$
  $$\frac{\partial L}{\partial \lambda_\rho} = [k_{\rho_0} - k_\rho] = 0;\; \rho=1,2,\ldots,m$$
  Получилась система из $n+m$ уравнений. Если решим систему, получим аналитическое решение задачи.
  
  \paragraph*{Пример}
  Задача имеет смысл, когда $p=1$\\
  $max\; p$ \\
  Есть:\par
  m - масса \par
  v - объём \par
  c - экономия \par
  p - вероятность безотказной работы
  $$max\; p$$
  $$m(v,c) \leq m(v_0,c_0)$$
  \begin{center}
	либо $min(m,v,c)$ при $p \geq p_0$
  \end{center}
  
  \section{Поисковые методы}
  Последовательное вычисление, причём следующий шаг должен быть лучше предыдущего.\par
  Рассмотрим условия, когда локальный экстремум является глобальным. Рассмотрим понятия выпуклой и вогнутой функции.\\
  $$z = \lambda (k(\bar{q}') + (1-\lambda)k(\bar{q}''))$$  
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[below=4pt] {$q$};
  	\draw[->] (0,-0.5)--(0,4) node[left] {$k$};
  	\draw[dashed] (1.5,0) node[below] {$q'$} -- ++(0,1.5) -- ++(3,1) -- ++(0,-2.5) node[below] {$q''$};
  	\draw (1.5,1.5) .. controls (2,2) and (3,3) .. (4.5,2.5);
  	\draw (1.5,1.5) .. controls (2,1) and (4,1.5) .. (4.5,2.5);
  	\draw (4,3) -- ++(0.5,0.75) node[above] {Выпуклая};
  	\draw (4,1.75) -- ++(1,-0.25) node[right] {Вогнутая};
  \end{tikzpicture}
  $$k[\lambda \bar{q}' + \left(1-\lambda q''\right)] \leq Z = \lambda k(\bar{q}') + (1-\lambda)k(\bar{q}')$$
  Если знак неравенства $\leq$ - имеем дело с выпуклой функцией.\\
  Если неравенство строгое - строго выпуклая функция.\\
  Если знак $\geq$, то функция вогнутая.\\
  Если $=$, то не строго выпуклая и не строго вогнутая.\par
  Если на выпуклом множестве определена \emph{вогнутая} функция, тогда локальный \emph{максимум} является глобальным. Если же на выпуклом множестве определена \emph{выпуклая} функция, тогда локальный \emph{минимум} является глобальным.
  
  \section{Метод Гаусса-Зейделя}
  Функция $k(q_1, q_2, \ldots, q_n);\;q_1, q_2, \ldots, q_n = const $
  \begin{enumerate}
    \item $max(min(k(q_1)))$ \\
      \begin{tikzpicture}
  	    \draw[->] (-0.5,0)--(4,0) node[anchor=north] {$q_1$};
  	    \draw[->] (0,-0.5)--(0,4) node[anchor=east] {$q$};
  	    \draw (2,2) -- +(-0.5,0) -- +(-0.5,0.5) -- +(0.5, 0.5) -- +(0.5,-0.5) -- +(-1,-0.5) -- +(-1,1) -- +(1,1) -- +(1,-1) -- +(-1,-1);
      \end{tikzpicture}
    \item $min(max(k(q_1)))$ \\
      \begin{tikzpicture}
        \draw[->] (-0.5,0)--(4,0) node[anchor=north] {$q$};
  	    \draw[->] (0,-0.5)--(0,4) node[anchor=east] {$k$};
  	    \draw (1,1) -- ++(1,0) -- ++(0,1) -- ++(0.5,0) -- ++(0,0.5) -- ++(0.25,0) -- ++(0,0.25) -- ++(0.12,0);
      \end{tikzpicture}
  \end{enumerate}
  $$|q_i^{r+1} - q_i^r| \leq \epsilon_i - q_n$$
  $$|k^{r+1} - k^r| \leq \eta $$
  Недостаток: плохая сходимость. Обычно решается для $n<3$.

  \section{Градиентный метод оптимизации (первого порядка)}
  Идея: ищут стационарную точку (безусловный экстремум) равных значений показателя.\\
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(6,0) node[anchor=north] {$q_1$};
  	\draw[->] (0,-0.5)--(0,5) node[anchor=east] {$q_2$};
  	\draw (3,2.9) circle[x radius=2mm, y radius=1mm, rotate=30];
  	\draw (2.5,2.5) .. controls +(1mm,6mm) and +(-1mm,4mm) .. (3.5,3)
  					.. controls +(0,-4mm) and +(0,-2mm) .. (2.5,2.5);
  	\draw (2,2) .. controls +(0,1) and +(-0.25,0.25) .. (3,3.5)
  				.. controls +(0.3,-0.2) and +(0.5,1) .. (3.5,2.5)
  				.. controls +(-0.2,-0.5) and +(0,-0.3) .. (2,2);
  	\draw (1.5,1.5) .. controls +(0.1,2.5) and +(0.3,2) .. ++(3	,2)
  					.. controls +(0,-1) .. ++(-0.5,-1.5)
  					.. controls +(-0.5,-0.5) and +(-0.1,-0.8) .. (1.5,1.5);
  	\coordinate (a) at (1,2);
  	\coordinate (b) at ($(a) +(49:4cm)$);
  	\draw[help lines] (a) -- (b);
  	\coordinate (c) at ($ (a)!0.50!(b) $);
  	\coordinate (d) at ($ (c)!1cm!-90:(b) $);
	\draw[help lines] (c) -- (d);
  	\draw (4.3,4.7) -- ++(1,0.25) node[anchor=west] {кривые равных значений};
	\draw (5.3,4.6) node[anchor=west] {показателя};
  \end{tikzpicture}\\
  Направление крутого восхождения:
  $$
    \nabla k(\bar{q}^{\,r}) =
    \begin{bmatrix}
      \frac{\partial k}{\partial q_1}\\
      \frac{\partial k}{\partial q_2}\\
      \vdots\\
      \frac{\partial k}{\partial q_n}\\
    \end{bmatrix}
  $$
  \par
  Направление наибольшего возрастания показателя и будет направлением градиента.
  \par
  Противоположное ему направление называется антиградиентом(отрицательным градиентом).
  \par
  С каждым шагом мы вычисляем новое направление градиента, с тем чтобы двигаться к экстремуму.
  $$\bar{q}^{\,2+1} = \bar{q}^{\,2} + \Theta\nabla k(\bar{q}^{\,(2)})$$
  $$\bar{q}_i^{\,2+1} = \bar{q}^{\,2} + \Theta\bigg(\frac{\partial k}{\partial q_i}\bigg)_k$$
  \par
  Иногда вектор градиент нормируется
  $$\nabla k^{\,r}_{\,n}(q^{\,r}) = \frac{\Delta k(q_2)}{\Big[\sum_{k=1}^n\big(\frac{\partial k}{\partial q_i}\big)\Big]^{\frac{1}{2}}}$$
  Выбор шага:
  \begin{enumerate}
    \item Метод с постоянным шагом
    \item С оптимальным шагом
  \end{enumerate}
  \section{Метод с оптимальным шагом}
  Есть $k$ в точке $r+1$
  $$k(\bar{q}^{r+1}) = k[\bar{q}^r + \Theta\nabla k(\bar{q}^r)]$$
  Ищем $\Theta$, которое соответствует $max(k(q^{r+1}))$ и $min$, если мы решаем задачу на минимум.\\
  Мы свели задачу многомерной оптимизации к задаче одномерной оптимизации. Условная функция должна быть гладкая и должны существовать по крайней мере две производные; и матрица Гессе должна быть знакоопределённая.\\
  Если мы попадём в седло, то из этой точки надо вылезать с помощью другого метода. Если функция гладкая и имеет 3 производных, то градиентный метод сходится при $r \rightarrow \infty$. Если функция квадратичная, то мы приходим к экстремуму за конечное число шагов.
  \paragraph*{Ограничение значений параметра}
  \begin{tikzpicture}
    \draw[->] (-0.5,0)--(7,0) node[anchor=north] {$q_1$};
  	\draw[->] (0,-0.5)--(0,5) node[anchor=east] {$q_2$};
    \draw (1,1) rectangle (6,4);  	
  	\coordinate (a) at (2,2.5);
  	\coordinate (b) at (5.5,5);
  	\coordinate (c) at ($ (a)!0.60!(b) $);
  	\draw                             (a) -- (b);
  	\draw [decorate,decoration={brace,raise=5pt}] (a) -- (b) node[pos=0.45,above=10pt] {$\Theta_{\text{опт}}$};
  	\draw [decorate,decoration={brace,mirror,raise=5pt}] (a) -- (c) node[pos=0.7,below=12pt] {$\Theta_{\text{доп}}$};
  	\draw[->] (5.25,4) -- +(0,-1);
  	\node[cross out, draw, inner sep=3pt] at (5.25,4) {};
  \end{tikzpicture}
  $$\Theta_r = min[\Theta_{\text{доп}} - \Theta_{\text{опт}}]$$
  $$\Theta_{\text{доп}} - \text{допустимое}$$
  $$\Theta_{\text{опт}} - \text{оптимальное}$$
  Отбрасываем переменную, которая вышла за границу и пытаемся решить задачу без неё. Вычисляем производную по $q_2$. Если она направлена вниз, то мы движемся внутрь области, если вверх - за пределы области; считаем эту точку оптимальной.\\
  Преимущества: 
  \begin{itemize}
    \item Классический эталонный метод.
  \end{itemize}
  Недостатки: 
  \begin{itemize}
    \item Сложность вычисления производных.
    \item Численные методы могут давать большие ошибки.
    \item Метод по своей сути не рассчитан на учёт ограничений.
  \end{itemize}
  \section{Градиентный метод (второго порядка)}
  $$k(q^{\,r+1}) = k(\bar{q}^{\,r}) + \sum_{i = 1}^n\bigg(\frac{\partial k}{\partial q_1}\bigg)_r\Delta q_ir + \frac{1}{2}\sum^{n}_{i,j=1}\bigg(\frac{\partial^{\,2}k}{\partial q_i\partial q_j}\bigg)_r\Delta q_ir\Delta q_jr$$
  $$\Delta q_ir = q_i^{\,r+1} - q_i^{\,r}$$
  \par
  В матричной форме
  \begin{equation}\label{eq:quad}
    \phi^{\,2} = \overbracket[0.5pt][7pt]{\nabla^{\,T}\underset{\mathclap{\begin{matrix}\uparrow\\\text{\scriptsize{вектор}}\\\text{\scriptsize{строка}}\end{matrix}}}{k}(\bar{q}^{\,r})\bar{\Delta}\underset{\mathclap{\begin{matrix}\uparrow\\\text{\scriptsize{вектор}}\\\text{\scriptsize{столбец}}\end{matrix}}}{q^{\,2}}}^{\mathclap{\text{при умножении получается число}}}+\frac{1}{2}(\Delta\bar{q}^{\,r})^{\,T}\mathcal{J}(\bar{q}^{\,r})_\Delta\bar{q}^{\,r}
  \end{equation}
  \par
  \ref{eq:quad} - квадратичная форма.
  \begin{equation}\label{eq:up}
    \frac{\partial \phi^{\,r}}{\partial \bar{\Delta}q^{\,r}}
  \end{equation}
  \par
  \ref{eq:up} - метод наискорейшего восхождения(спуска, если решаем задачу на $min$)
  \par
  В формуле \ref{eq:quad} возьмем производную по первому и второму слогаемому
  $$\nabla k(\bar{q}^{\,r}) + \mathcal{J}(\bar{q}^{\,r})\Delta\bar{q}^{\,r} = 0$$
  $$\mathcal{J}(q\,')\bar{\Delta} q^{\,r} = \nabla k(\bar{q}^{\,r})$$
  \par
  Умножаем на матрицу, обратную матрице $\mathcal{J}$.
  $$\underbrace{\mathcal{J}^{\,-1}(\bar{q}^{\,r})\mathcal{J}(\bar{q}^{\,r})}_{\mathclap{\text{E - единичная матрица}}}\bar{\Delta}q^{\,r} = \mathcal{J}^{\,-1}(q^{\,2})\nabla k(\bar{q}^{\,2})$$
  \par
  \begin{equation}\label{eq:cool}
    \bar{\Delta}q^{\,r} = \mathcal{J}^{\,-1}(q^{\,r})\nabla k(\bar{q}^{\,r})
  \end{equation}
  \par
  \ref{eq:cool} - направление самого крутого восхождения или наискорейшего спуска.
  \begin{equation}
    \bar{q}^{\,r+1} = \bar{q}^{\,r} - \Theta\mathcal{J}^{\,-1}(\bar{q}^{\,r})\nabla k(\bar{q}^{\,r})
  \end{equation}
  \par
  Окончательное выражение для градиентного метода второго порядка(метода Ньютона)
  \par
  Если функция $k$ - квадратичная, то оптимальная точка достигается за один шаг и точка берется равной 1.
  $$
    \mathcal{J} =
    \begin{bmatrix}
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{bmatrix}
  $$
  $$
    \tilde{\mathcal{J}} =
    \begin{bmatrix}
      a_{11} & -a_{12}\\
      -a_{21} & a_{22}
    \end{bmatrix}
  $$
  $$
    \mathcal{J} = \frac{1}{\Delta}\mathcal{J}
  $$
  \paragraph*{Задача}
  $$k = (q_1 - 5)^2 + (q_2 - 8)^2 + (q_1 - q_2)^2$$
  Найти минимум функции.\\
  Начальные условия:\\
  $q^0 = 
  \begin{bmatrix}
    0 \\ 
    0    
  \end{bmatrix}$
  $$\frac{\partial k}{\partial q_1} = 2(q_1 - 5) + 2(q_1 - q_2) = -10$$
  $$\frac{\partial k}{\partial q_2} = 2(q_2 - 8) - 2(q_1 - q_2) = -16$$
  $$\frac{\partial^2k}{\partial q_1^2} = 2 + 2 = 4$$
  $$\frac{\partial^2k}{\partial q_2^2} = 2 + 2 = 4$$
  $$\frac{\partial^2k}{\partial q_1 \partial q_2} = -2$$  
  $$\mathcal{J} = 
  \begin{bmatrix}
    4 & -2 \\
    -2 & 4
  \end{bmatrix} - \text{Матрица Гессе}$$
  $$\mathcal{\tilde{J}} = 
  \begin{bmatrix}
    4 & 2 \\
    2 & 4
  \end{bmatrix}  
  $$
  $$\Delta = 16 - 4 = 12$$
  $$\mathcal{J}^{-1}(\bar{q}) = \frac{1}{12}\begin{bmatrix}
    4 & 2 \\
    2 & 4
  \end{bmatrix}$$
  $$\nabla k = \begin{bmatrix}
    -10 \\
    -16
  \end{bmatrix}$$
  Всё это справедливо только в нулевой точке.
  $$\bar{q}_0 = \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} - \begin{bmatrix}
    \frac{1}{3} & \frac{1}{6} \\[0.3em]
    \frac{1}{6} & \frac{1}{3}
  \end{bmatrix} \ast \begin{bmatrix}
    -10 \\
    -16
  \end{bmatrix} = \begin{bmatrix}
    0 \\
    0
  \end{bmatrix} + \begin{bmatrix}
    \frac{1}{3}\cdot 10 + \frac{1}{6}\cdot 16 \\
    \frac{1}{6}\cdot 10 + \frac{1}{3}\cdot 16
  \end{bmatrix} = \begin{bmatrix}
    6 \\
    7
  \end{bmatrix}$$
  \textit{Перемножение матриц: первая строка на первый столбец; вторая строка на первый столбец.}\\
  Преимущество: высокая скорость сходимости.
  Недостаток: сложность вычисления матрицы Гессе. 
\end{document}
